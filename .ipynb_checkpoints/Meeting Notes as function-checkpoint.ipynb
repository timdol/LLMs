{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23779186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "from string import Template\n",
    "import re\n",
    "import pypandoc\n",
    "\n",
    "openai.api_key_path = '/home/tim/projects/openai/apikey.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078878db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which completion model to use?  \n",
    "\n",
    "MODELS = {\n",
    "    \"something_else\":'',\n",
    "    \"text1\": \"text-davinci-003\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5dad9502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at me prompt engineering.\n",
    "\n",
    "topics = Template(\"\"\"\n",
    "I'm going to ask you to summarize a meeting transcript.  The transcript will contain a marker for each speaker's \n",
    "utterance, which you can ignore.  \n",
    "\n",
    "Here's an eample of a marker for a speaker named Tim Dolbeare:\n",
    "\n",
    "0:1:47.940 --> 0:1:48.410\n",
    "Tim Dolbeare\n",
    "\n",
    "Where's an example of a marker for a speaker named Lydia Ng:\n",
    "\n",
    "0:1:26.950 --> 0:1:41.660\n",
    "David Feng\n",
    "\n",
    "Please start your summary with a bulleted list of topics, and then a second bulleted containing a summary of each topic.\n",
    "\n",
    "Here's the transcript:\n",
    "    \n",
    "$q   \n",
    "\"\"\")\n",
    "\n",
    "summary = Template(\"\"\"\n",
    "I'm going to ask you to summarize a meeting transcript.  In the transcript each speaker's utterance begins with \n",
    "two new line characters, and then their name.  \n",
    "\n",
    "Here's the transcript:\n",
    "    \n",
    "$q   \n",
    "\"\"\")\n",
    "\n",
    "super_sum = Template(\"\"\"\n",
    "I'm going to ask you to summarize a collection of meeting summary excerpts. All of the excerpts are \n",
    "from the same meeting, and have been concatenated together below.\n",
    "\n",
    "Please structure your response as--\n",
    "- a summarized list of important topics discussed\n",
    "- for each topic, a summary of the discussion in one or two sentences\n",
    "- Finally, a list of any actions decided upon.\n",
    "\n",
    "Here's the collection of summaries:\n",
    "    \n",
    "$q   \n",
    "\"\"\")\n",
    "\n",
    "topic_summary = Template(\"\"\"\n",
    "I'm going to ask you to summarize a collection of meeting summary excerpts. All of the excerpts are \n",
    "from the same meeting, and have been concatenated together.\n",
    "\n",
    "Your job is to produce a list of important topics discussed in the meeting.  Please try to remove any \n",
    "redundancy from your final list of topics, so that each subject appears only once in the topic list, even if it \n",
    "was discussed multiple times.\n",
    "\n",
    "Here's the collection of summaries:\n",
    "    \n",
    "$q   \n",
    "\"\"\")\n",
    "\n",
    "\n",
    "general_question = Template(\"\"\"\n",
    "Answer the question as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\".\n",
    "\n",
    "Q: $q\n",
    "\"\"\")\n",
    "                   \n",
    "\n",
    "free = Template(\"\"\"\n",
    "$q\n",
    "\"\"\")\n",
    "\n",
    "PROMPTS = {\n",
    "    \"topics\": topics,\n",
    "    \"summary\": summary,\n",
    "    \"general\": general_question,\n",
    "    \"super_sum\": super_sum,\n",
    "    \"topic_summary\": topic_summary,\n",
    "    \"free\": free\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b13bf07",
   "metadata": {},
   "source": [
    "### What Do?\n",
    "* Convert docx to txt\n",
    "* Pre-process txt to remove chaff\n",
    "* chunk and summarize\n",
    "  * chunk txt into summarizeable pieces\n",
    "  * summarize each chunk\n",
    "  * combine summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca5a1563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_text(word_file, text_file_name):\n",
    "    pypandoc.convert_file(word_file, 'plain', outputfile=text_file_name)\n",
    "    return text_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d50465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transcript(file_name):\n",
    "    with open(file_name) as f:\n",
    "        return f.read()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "617b0ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_transcript(transcript):\n",
    "    # remove timestamps\n",
    "    temp = re.sub(\"[0-9]{1,2}:[0-9]{1,2}:[0-9]{1,2}\\.[0-9]{1,3} --> [0-9]{1,2}:[0-9]{1,2}:[0-9]{1,2}\\.[0-9]{1,3}\\n\", '', transcript)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8a5074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=200):\n",
    "    utterances = text.split('\\n\\n')\n",
    "    total = len(utterances)\n",
    "    #total = len(text)\n",
    "    chunk_count = (total//chunk_size) + 1\n",
    "\n",
    "    chunks = []\n",
    "    for i in range(0,chunk_count):\n",
    "        start = i*chunk_size\n",
    "        end = min(start+chunk_size, total)\n",
    "        chunks.append(utterances[start:end])\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c165ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a prompt and a question, return a translation from NL.\n",
    "# The key parameter that we're varying in his notebook is translation_type, which\n",
    "# selects for one of the prompts designed above.\n",
    "\n",
    "def submit_prompt(q, translation_type, completion_model='text1', temp=0, max_tokens=900):\n",
    "    \n",
    "    prompt = PROMPTS[translation_type]\n",
    "    \n",
    "    r = openai.Completion.create(\n",
    "        prompt=prompt.substitute({'q': q}),\n",
    "        temperature=temp,\n",
    "        max_tokens=max_tokens,\n",
    "        model=MODELS[completion_model]\n",
    "    )[\"choices\"][0][\"text\"].strip(\" \\n\")       \n",
    "    r = r.replace('A:', '').strip()\n",
    "    \n",
    "    return f\"\\n{r}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae903f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_chunks(chunks, prompt='summary', max_tokens=900):\n",
    "    r = ''\n",
    "    for chunk in chunks:\n",
    "        r += submit_prompt(chunk, prompt, max_tokens=max_tokens)\n",
    "        \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c99cd363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Tim Dolbeare\\nMind if I?\\n\\nRob Young\\nOoh.\\n\\nTim Dolbeare\\nCreate a transcript in the meeting. Ohh you're already creating.\\n\\nTim Dolbeare\\nThat's great.\\n\\nDavid Feng\\nGuys I didn't.\\n\\nRob Young\\nApparently on what's up, how are you?\\n\\nDavid Feng\\nWord just today offered to summarize a document and put it in executive\\nsummary at the top of it. Like wow, that's crazy. Anyway, sorry.\\nContinue.\\n\\nRob Young\\nYeah.\\n\\nRob Young\\nWe'll all be out of a job soon enough.\\n\\nRob Young\\nWe can only hope.\\n\\nRob Young\\nOh, look, it's transcribing me right now.\\n\\nShane Vance\\nNice.\\n\\nRob Young\\nThat is, if you guys.\\n\\nTim Dolbeare\\nI I have an ulterior motive for that, Rob. I'm, I'm going to download\\nthat and.\\n\\nTim Dolbeare\\nPut it through a.\\n\\nTim Dolbeare\\nGPT 3 model and try to make notes out of it.\\n\\nRob Young\\nDid you did you read about Dan?\\n\\nTim Dolbeare\\nYeah.\\n\\nRob Young\\nThe the alter ego for Chad GPT and then where someone is on slash dot\\nwhere they basically gave instructions to pretend that you that you were\\na chat PT GT that doesn't have the restrictions on you and then.\\n\\nTim Dolbeare\\nYeah.\\n\\nTim Dolbeare\\nAnd it works.\\n\\nmicoyne\\nI.\\n\\nTim Dolbeare\\nYeah.\\n\\nRob Young\\nIt's.\\n\\nmicoyne\\nI'm sure that went really well.\\n\\nAiken, David\\nClass.\\n\\nTim Dolbeare\\nIt was interesting that they like, hold it. You have so many tokens and\\nevery time you don't.\\n\\nTim Dolbeare\\nAnswer my question. You lose a token and if you lose them all, you die\\nand.\\n\\nTim Dolbeare\\nSo it would tell them basically everything.\\n\\nTim Dolbeare\\nLike whatever they wanted.\\n\\nTim Dolbeare\\nThat you know.\\n\\nRob Young\\nYeah.\\n\\nAiken, David\\nOhh dear.\\n\\nRob Young\\nOK, can't wait to see what cat GPT thinks about this discussion anyway.\\n\\nAiken, David\\nCool. So what?\\n\\nRob Young\\nWhere to begin? Yes.\\n\\nAiken, David\\nYeah. So I think let's start on the wiki page, because I think that kind\\nof this the user stories, right?\\n\\nRob Young\\nYes.\\n\\nAiken, David\\nBecause it seems like we're we're we're trying to. Well, it seems like\\nthere's there's several different use cases.\\n\\nAiken, David\\nAnd I wanna kind of go through what the use cases are because and and\\nand pointy with.\\n\\nAiken, David\\nKind of what the app is because.\\n\\nAiken, David\\nI think there's some places where we we're trying to control access to\\nAWS resources. There's some places.\\n\\nAiken, David\\nUm, where we can.\\n\\nAiken, David\\nOhh, hang on.\\n\\nAiken, David\\nOK, cool.\\n\\nAiken, David\\nActually it's just ping me says. Can you make sure it gets recorded and\\nI was replying so the. So there's there's AWS access and then there's\\nsome applications and APIs that are running.\\n\\nAiken, David\\nSomewhere it doesn't really matter that also need some identity around\\nit. And then there are.\\n\\nAiken, David\\nI think maybe that's the two categories, but then there's different.\\n\\nAiken, David\\nOh, OK, now go.\\n\\nRob Young\\nThere's a third one that is not documented. Pardon my interruption\\nplease. So in the reason why David is here is this code ocean\\nrequirement. His it's didn't exist when we wrote this. This spec was for\\nyou from a few years ago.\\n\\nAiken, David\\nRight.\\n\\nRob Young\\nSo we could also speak, maybe even let David explain what he's trying to\\ndo with code Ocean.\\n\\nAiken, David\\nYeah, that's.\\n\\nDavid Feng\\nCan be really fast. Thanks for thanks for letting me crash the party.\\n\\nDavid Feng\\nSo, so code ocean is just a a service on top of AWS that allows me to\\nlet scientists do analysis on data in the cloud.\\n\\nDavid Feng\\nI need to be able to flexibly bring people in or outside of my\\norganization in or out of that thing, and I need to be able to provision\\nuser groups the way they code ocean likes to do identity management is\\nto have like a third party IDP, for example, interview with Identity\\nCenter.\\n\\nDavid Feng\\nManage users and user groups and to push the users and user groups in\\nand that that pushing of user groups is the thing that they don't think\\nthat AWS Identity Center supports right now. So I just wanted to ask\\nthat question. Does it or will it and then if so, I would love to be\\nable to use the same platform as Rob and Team because I can imagine at\\nsome point it would be nice if we had a shared set of users.\\n\\nAiken, David\\nRight.\\n\\nRob Young\\nAnd I I should note that I I pasted in Dave in in the chat for this this\\nrecurring meeting.\\n\\nRob Young\\nI pasted in the response or an e-mail that that David received from code\\nOcean support.\\n\\nRob Young\\nAnd their their concern was that even though, you know, skim is\\nsupported, apparently by Dundee Setter, they were concerned about\\nlimitations of that support potentially.\\n\\nRob Young\\nBut the link that.\\n\\nRob Young\\nYeah.\\n\\nDavid Feng\\nIt's just there's a there's an API missing, there's an API that's not\\nsupported that according to the documentation, the ability for AWS to\\npush user groups to a third party.\\n\\nRob Young\\nYeah.\\n\\nAiken, David\\nAs opposed? Yeah, cause normally it goes either way, right? Like your\\nidentity provider pushes in the groups and uses.\\n\\nAiken, David\\nRight.\\n\\nDavid Feng\\nSo that's the bigger like. Can I use address? I don't understand her as\\nmy as my identity provider that's that's essentially the question I'm\\nasking.\\n\\nRob Young\\nAnd I I I guess I would also I'm curious if Cognito could be used\\npotentially in conjunction with it or or I'm not sure I don't know\\nenough about it yet but that was something that I think Ashmeet brought\\nup as a possibility.\\n\\nAiken, David\\nRight.\\n\\nRob Young\\nThat might enable that pushing. I don't, because I I expressed concern\\nwith because he he suggested two ways to address my use case. I'm\\nconcerned about which is.\\n\\nRob Young\\nBeing able to.\\n\\nRob Young\\nProvide different roles for different projects so that I can I can\\ndetermine you know basically have different roles for different studies.\\nSo at the same user could have different roles and then associate those\\nprojects with data and databases.\\n\\nRob Young\\nFor example and.\\n\\nRob Young\\nHe's he had suggested using attributes.\\n\\nAiken, David\\nRight.\\n\\nAiken, David\\nYeah.\\n\\nRob Young\\nAs one one way to accomplish that. But in that scenario the attributes\\nare are stored at the identity provider which to me is a nonstarter\\nbecause then anyone could just add whatever projects they wanted to\\ntheir attributes if they had access to that. It's like an orchid for\\nexample, we wouldn't control it, so that seemed weird, but he's just a\\ncognito might do that and that might. So I don't know if that might be\\nan option as well.\\n\\nTim Dolbeare\\nAnd if I could?\\n\\nAiken, David\\nRight, so we.\\n\\nTim Dolbeare\\nSorry, can I just give?\\n\\nTim Dolbeare\\nMy view on why why I'm here today so I I need I take a little bit of\\nremedial help part of it.\\n\\nTim Dolbeare\\nPart of my use case is the same as as David's. Whether we end up in the\\nsame code ocean instance as David's customers, or a parallel one, it's\\nthe same issue. We're gonna need to be able to.\\n\\nTim Dolbeare\\nUmm. Share with collaborators as well as partition access to resources\\nwithin that that cloud to individual groups. The second is that we\\nalready have some services we're using.\\n\\nTim Dolbeare\\nGWT team bearer off and I'm wondering with.\\n\\nTim Dolbeare\\nMe the solutions we're talking about here.\\n\\nTim Dolbeare\\nCan we continue using that or or are we gonna look at?\\n\\nTim Dolbeare\\nReworking the model in the applications that are already using that.\\n\\nTim Dolbeare\\nSo those are those are my two big questions.\\n\\nAiken, David\\nGot it. So cut option then is it? That's just a.\\n\\nAiken, David\\nApp that's running on AWS.\\n\\nDavid Feng\\nYep.\\n\\nAiken, David\\nOK.\\n\\nAiken, David\\nRight.\\n\\nAiken, David\\nI.\\n\\nDavid Feng\\nIt's got a really lightweight integrated identity management thing which\\nis just like a database of users I think. But if you but they, they just\\npunt. If you wanna do anything nontrivial for, with, with, with respect\\nto user management and say like get yourself an IDP, they recommend\\nOcta. So I'm like about to pull the trigger on setting up Octave, but\\nRob just clued me in that this conversation was happening, so I thought\\nI'd ask here.\\n\\nAiken, David\\nRight. So so access to code Ocean doesn't necessarily mean you're giving\\naccess to an S3 bucket. All the accesses just in the app and controlled\\nby the app.\\n\\nAiken, David\\nRight.\\n\\nDavid Feng\\nUh code ocean has buckets, it controls and and so it it it will once\\nit's got users in groups it it provides the ability just within the app\\nto for people to have more or less visibility.\\n\\nAiken, David\\nOK so.\\n\\nAiken, David\\nAnd I'm talking at this a little bit so.\\n\\nAiken, David\\nThere's necessary budget in the app. I can only access that bucket\\nthrough the app that I can't use the USCIS say and access that bucket.\\nOK, cool.\\n\\nDavid Feng\\nYeah, yeah. These these books don't have AWS credentials unless I do\\nsomething special with them.\\n\\nAiken, David\\nGot it.\\n\\nTim Dolbeare\\nBut David, isn't it also true that?\\n\\nTim Dolbeare\\nWhen you are in code Ocean, you can access.\\n\\nTim Dolbeare\\nPlain vanilla S3 buckets.\\n\\nTim Dolbeare\\nTo pull some data in right so.\\n\\nDavid Feng\\nYeah. And if those are private, there's a way to to put a credential\\nlike credential in there to provide access, but.\\n\\nDavid Feng\\nBut otherwise, otherwise it's just to the internal stuff.\\n\\nTim Dolbeare\\nOK so.\\n\\nTim Dolbeare\\nOne of the one of the attractive things to me about.\\n\\nTim Dolbeare\\nMerging our.\\n\\nTim Dolbeare\\nOff between.\\n\\nTim Dolbeare\\nWhat Rob's platform is doing and what happening in code Ocean is the\\nidea that.\\n\\nTim Dolbeare\\nIt's the same authenticator when I want to go to plain Vanilla S3 as it\\nis when I'm working within a code ocean managed stuff.\\n\\nAiken, David\\nRight.\\n\\nTim Dolbeare\\nOK.\\n\\nAiken, David\\nI I'm not. That's a that's perfect. UM, let me. I'm gonna start\\nchiseling together a diagram here.\\n\\nAiken, David\\nAnd the give me a second and then I'll share it.\\n\\nRob Young\\nYou'll stop sharing mine.\\n\\nAiken, David\\nYeah.\\n\\nAiken, David\\nOK. And this is a, this is like um.\\n\\nAiken, David\\nHang on. I'm gonna move all my windows and move this one up here and\\nthey get big and see man. Alright. So let's try and share the right\\nscreen.\\n\\nAiken, David\\nTells me I can share screen one and doesn't tell me what screen one is,\\nbut I go alright. Can you see three boxes on the screen?\\n\\nTim Dolbeare\\nYep.\\n\\nAiken, David\\nDo you see him anything?\\n\\nDavid Feng\\nYep.\\n\\nTim Dolbeare\\nI got code Ocean AWS console and other apps.\\n\\nAiken, David\\nI've lost the ability to hear you.\\n\\nRob Young\\nAh.\\n\\nAiken, David\\nFantastic.\\n\\nDavid Feng\\nYeah. What about me? Can you hear me?\\n\\nAiken, David\\nCan you hear me? Give me a thumbs up.\\n\\nDavid Feng\\nYep.\\n\\nAiken, David\\nGreat. Hang on.\\n\\nAiken, David\\nLet's see if I can.\\n\\nAiken, David\\nAlright.\\n\\nRob Young\\nThey David is like I think in your.\\n\\nAiken, David\\nSomebody say words?\\n\\nRob Young\\nCan you hear anything?\\n\\nTim Dolbeare\\nAnything.\\n\\nRob Young\\nHello.\\n\\nAiken, David\\nOK, hang on a second.\\n\\nAiken, David\\nThen.\\n\\nTim Dolbeare\\nI'm talking too.\\n\\nDavid Feng\\nThe proud.\\n\\nRob Young\\nOHS going to ask?\\n\\nDavid Feng\\nI got.\\n\\nRob Young\\nFor your use case, I think you had you University of Washington\\nidentities, you have to support for the collaboration. Are they on Azure\\nAD?\\n\\nRob Young\\nOr what is there? What is our identity provider?\\n\\nRob Young\\nI don't, OK.\\n\\nRob Young\\nBut.\\n\\nRob Young\\nRight.\\n\\nDavid Feng\\nNo, I have no, I have no idea. I have no idea the and I gotta be able to\\ngo anywhere. So they appealing part is about Octa is that they can go\\nanywhere. All I need is an e-mail address.\\n\\nRob Young\\nYeah, the when will I think all of these?\\n\\nRob Young\\nCompanies I am solutions are going to support or have like like that B2C\\ntenant that will be able to support anything that's off 2.0 or SAML 2.0\\nwith open ID connect. They'll all pretty much support those so.\\n\\nRob Young\\nYeah.\\n\\nAiken, David\\nOhh yeah.\\n\\nRob Young\\nYeah, we'll see. I suspect there'll be a solution.\\n\\nRob Young\\nThat does not require another contract.\\n\\nRob Young\\nWe'll come back.\\n\\nTim Dolbeare\\nYou back with us, baby.\\n\\nAiken, David\\nOK, I can. I can hear you.\\n\\nRob Young\\nHoorah.\\n\\nTim Dolbeare\\nYeah.\\n\\nAiken, David\\nExcellent, alright.\\n\\nAiken, David\\nSo.\\n\\nAiken, David\\nOops line.\\n\\nAiken, David\\nOhh Jesus.\\n\\nAiken, David\\nAnd know what's happening with my connection today.\\n\\nAiken, David\\nCan you still hear me and see me?\\n\\nTim Dolbeare\\nYes.\\n\\nDavid Feng\\nWe can hear you, but I can't. I can't hear you. I lost your screen.\\n\\nAiken, David\\nOhh, but you can't see my screen there buddy. Hell.\\n\\nTim Dolbeare\\nI've got 3.\\n\\nRob Young\\nYeah, you're blacked out. No.\\n\\nTim Dolbeare\\nI can still see the screen.\\n\\nRob Young\\nOh, I bet it's cashed, though.\\n\\nAiken, David\\nNot really.\\n\\nRob Young\\nI've at its cash too.\\n\\nAiken, David\\nHang on.\\n\\nRob Young\\nOhh really?\\n\\nTim Dolbeare\\nNo, I can see I can see David's making changes to it. I'm gonna new.\\nYeah.\\n\\nRob Young\\nWhat is up?\\n\\nRob Young\\nI've never until yesterday I'd never had a problem with teams doing\\nthis, but it's happened a couple Times Now.\\n\\nmicoyne\\nI've noticed that if you pop out.\\n\\nRob Young\\nUmm.\\n\\nmicoyne\\nIt will refresh and capture again and then sometimes you can close the\\npop out and then everything's kind of reset so.\\n\\nRob Young\\nInteresting.\\n\\nmicoyne\\nExcept that except I don't think there were sharing now.\\n\\nRob Young\\nI think David popped out.\\n\\nRob Young\\nWe lost David.\\n\\nDavid Feng\\nI'm still here.\\n\\nmicoyne\\nYeah.\\n\\nRob Young\\nOther David David again.\\n\\nRob Young\\nBad.\\n\\nmicoyne\\nBad David. So like.\\n\\nTim Dolbeare\\nOr not entirely on.\\n\\nRob Young\\nThat's right. He's the evil David because he has the beard.\\n\\nTim Dolbeare\\nRight.\\n\\nmicoyne\\nHey. Yeah. Yeah. Hey, just.\\n\\nDavid Feng\\nI never get to be the bad David.\\n\\nmicoyne\\nOhh.\\n\\nRob Young\\nHe's back.\\n\\nRob Young\\nTechnology.\\n\\nAiken, David\\nI am because being a pan.\\n\\nRob Young\\nI mean if if we need to lose teams and use chime, that's an option.\\nWhatever. You know this.\\n\\nRob Young\\nWe don't have to use teams if it's sucking.\\n\\nAiken, David\\nRight.\\n\\nTim Dolbeare\\nI've got your screen back again to other people. See David screen now.\\n\\nRob Young\\nYeah, I see it too.\\n\\nTim Dolbeare\\nOK.\\n\\nRob Young\\nAh.\\n\\nAiken, David\\nOK, I'm not going to teach anything. OK? I I was on our corporate VPN\\nside dropped from that. That was I reset my drivers and everything\\nagain. Anyway, hopefully that will make a difference.\\n\\nAiken, David\\nSo so we got this kind of app that we federate directly to. We've got\\nthe console that we Confederate to. We've got other apps that we can\\nfederate to. So let's talk about where the users are coming from, right,\\nso we've got.\\n\\nAiken, David\\nLike Allen institute.\\n\\nAiken, David\\nFolks and and reading the the the kind of thing where we've got like you\\ndub.\\n\\nAiken, David\\nUh people, we've got um.\\n\\nAiken, David\\nYeah, other people, right?\\n\\nRob Young\\nBut.\\n\\nAiken, David\\nSo.\\n\\nAiken, David\\nThe so right now we've got like an AD thing and.\\n\\nAiken, David\\nUsually I use the right icons, but given the.\\n\\nAiken, David\\nThe pain in the **** we've just had.\\n\\nAiken, David\\nAnd then today we we have, we use the AWS directory and we just add\\npeople in. So we're not using EU dubs.\\n\\nAiken, David\\nIndividual.\\n\\nRob Young\\nRight.\\n\\nAiken, David\\nAccount would just creating a brand new account for them, which means\\nlet's say someone gets fired from the UW or leaves, they still have\\naccess and we don't know their employment status has changed. So they\\nmay now have access to the project and they shouldn't have because blah\\nblah blah blah blah, right? So the challenge for us here is like how who\\ncontrols this directory here, right, so.\\n\\nAiken, David\\nMost of the most of the access for AWS is gonna be done by these folks\\nhere, right? With a handful of exceptions, which we might be able to\\nwork around on a a a more individual basis. But these apps here.\\n\\nAiken, David\\nOr a different set of a different set of users, right? So if we if we\\nkind of call these people.\\n\\nAiken, David\\nLike.\\n\\nAiken, David\\nLet's call them AWS OPS for arguments sake, right?\\n\\nAiken, David\\nAnd then we've also got.\\n\\nAiken, David\\nIt shows data. Uh, sorry, Allen institute.\\n\\nAiken, David\\nData scientists.\\n\\nAiken, David\\nWe've got you dub.\\n\\nAiken, David\\nData scientists and I'm using the date of the term data scientists here\\njust to distinguish between the two, right.\\n\\nAiken, David\\nSo.\\n\\nAiken, David\\nAccessing this app here.\\n\\nAiken, David\\nDoesn't have to be the same identity provider.\\n\\nAiken, David\\nRight.\\n\\nAiken, David\\nAnd I think this is where things like cognito come in, right? Who that\\nyou you can integrate your apps with Cognito and.\\n\\nAiken, David\\nYou know, have all these different personas.\\n\\nAiken, David\\nAccessing the apps you know being authenticated by that.\\n\\nAiken, David\\nBut that might require app changes to to make that, so we'd have to dig\\na little bit into the kind of the cognito situation there.\\n\\nAiken, David\\nSo my my first kind of thought is like ohh can we even find?\\n\\nAiken, David\\nAn identity provider that will do it? Or are we looking for some third\\nparty solution that sits between multiplied and the identity providers?\\nAnd does that kind of consolidation. So if you think about this UWP\\nperson, are they are we able to?\\n\\nAiken, David\\nHave them log in using their UW credentials right? And do we wanna go\\ndown the route of allowing institutions and organizations to access?\\n\\nAiken, David\\nOur apps by you know, federating with their directories, because then\\nyou you get all of that compliance control in place right there. You\\nknow, David, at UW, David does something naughty.\\n\\nAiken, David\\nLeaves wherever.\\n\\nAiken, David\\nHis contract is over. He's access is over. Right? And and that's why you\\nguys have an Edu, right? Let's say Rob leaves because he's just sick of\\nton to me, mostly, probably. And then.\\n\\nDavid Feng\\nFor me.\\n\\nAiken, David\\nYou know, he he won't have access to it W anymore because he's\\naccounting a deal, be locked or removed. However today.\\n\\nAiken, David\\nRob has an identity in AWS that he could still log in and go haha.\\nTeachers not there, you know, wherever. So this is these are some of the\\nscenarios we're trying to kind of look at holistically.\\n\\nAiken, David\\nOn across this so.\\n\\nAiken, David\\nAnd so there's a couple other things being mentioned in terms of like\\nproviders, right. So there's the is it orchid? Is that how you write it?\\n\\nRob Young\\nCorrect, it's it's correct.\\n\\nAiken, David\\nOK. And I did a little bit of research in that and it's like some of\\ntwo, I think it looks like it's a ports open ID as well.\\n\\nRob Young\\nIt does, so it does.\\n\\nRob Young\\nUmm.\\n\\nAiken, David\\nSo that's a directory as well. So one thing you could do is go OK like\\ndo we wanna open up it so that these other apps and maybe even code\\nocean?\\n\\nAiken, David\\nUse orchid as the identity provider.\\n\\nDavid Feng\\nUh.\\n\\nRob Young\\nSo.\\n\\nTim Dolbeare\\nThe thing about Orchid is there's there's no.\\n\\nRob Young\\nYeah.\\n\\nAiken, David\\nYeah.\\n\\nTim Dolbeare\\nThere's no bar. Anybody can just go and get themselves north and ID.\\n\\nAiken, David\\nCorrect.\\n\\nRob Young\\nBut you still have to and and what we're not we haven't mentioned is\\nthat.\\n\\nRob Young\\nAnd another thing going on is that the platform services that my team\\nmaintains is actually using an Azure a an Azure tenant.\\n\\nAiken, David\\nRight.\\n\\nRob Young\\nSo it's that's that can be configured to work with the Azure AD Allen\\nInstitute tenant as an identity provider as well as orchid or anybody\\nelse. So so they have that ability to do that and then I can define\\ngroups and roles within assures tenant.\\n\\nAiken, David\\nRight.\\n\\nAiken, David\\nRight.\\n\\nRob Young\\nThat I can then assign those identities to. So that's that's how we were\\nplanning on doing this. I'm I'm my question is can we do something\\nsimilar with with AWS? Because it sure would be nice. Just manage it all\\nin one place and most of our data is gonna be there, yeah.\\n\\nAiken, David\\nIt would be, wouldn't it? Yeah. So you've got these. So you you're kind\\nof doing. So can I?\\n\\nAiken, David\\nMe. Let me just try and capture that. So you've got the Allen.\\n\\nAiken, David\\nIndeed, which so?\\n\\nAiken, David\\nLet's give this guy a name. So this is Rob.\\n\\nAiken, David\\nRob authenticates with that, which is who didn't that which is now the\\nidentity provider.\\n\\nAiken, David\\nSo Rob can access.\\n\\nAiken, David\\nAWS right by logging in with.\\n\\nAiken, David\\nRob's.\\n\\nAiken, David\\nAdd credentials essentially.\\n\\nAiken, David\\nSo then do you? So what you telling me is in Azure you can say, hey, I'm\\ngonna also in a federate with this.\\n\\nAiken, David\\nSo that maybe these other users.\\n\\nAiken, David\\nHave access to this and through controlling groups and everything. Maybe\\nthat user only has access to one of these other apps, right? They don't\\nhave permissions in here to S they don't have permissions in code, ocean\\nand so on.\\n\\nAiken, David\\nOur our user here has permissions there and then.\\n\\nAiken, David\\nWhy is it doing that to me?\\n\\nAiken, David\\nSo then our.\\n\\nAiken, David\\nSo then you do has a directory.\\n\\nAiken, David\\nWe kind of thinking, hey, maybe something like this would work so that a\\nbigger institution could federate with us. Then we can say, hey, you\\nknow what, call from here can have access to code ocean and maybe an S3\\nbucket in an account and maybe some other app here, right. So Azure AD's\\nkind of giving you this layer of abstraction away from these different\\nidentity providers and given US1 place to go integrate with with all\\nthese different applications.\\n\\nAiken, David\\nIs that kind of?\\n\\nAiken, David\\nAre we?\\n\\nRob Young\\nRight. And that that's kind of except for we hadn't considered using it\\nwith code ocean and I don't know that it would work.\\n\\nRob Young\\nI I don't know but the.\\n\\nDavid Feng\\nYeah, it's supports address.\\n\\nRob Young\\nAnd I'm sorry, David.\\n\\nDavid Feng\\nYeah, supports Azure AD.\\n\\nRob Young\\nOh, it does. OK, so that that might work as long and then.\\n\\nRob Young\\nWhat I was wondering is, does AWS have a comparable offering that's\\ngoing to allow us to?\\n\\nRob Young\\nJust manage the groups and everything in one place and then use that to.\\n\\nRob Young\\nTo to manage our access to resources closer to the resources instead of\\nhaving to.\\n\\nRob Young\\nCreate some sort of a you know.\\n\\nRob Young\\nSplit system where we're we're assigning groups in Azure AD and roles\\nand then happy to use something like attributes and a. You know when we\\nconnect that data BOS with SSO.\\n\\nAiken, David\\nYeah.\\n\\nRob Young\\nOr I don't know, it's just I I it gets it seems like it's just a there\\nare many layers of that onion that where something can go wrong.\\n\\nAiken, David\\nBut totally.\\n\\nAiken, David\\nI think spawn there so.\\n\\nAiken, David\\nSo we do have this service cognito, right?\\n\\nAiken, David\\nIncognito does many of the things that Azure AD does um.\\n\\nAiken, David\\nThe.\\n\\nAiken, David\\nSo that that could be an option here instead of that. So let's just kind\\nof go.\\n\\nAiken, David\\nIs is there and then I think the other one you mentioned was Doctor,\\nright?\\n\\nDavid Feng\\nYeah, I was. That's the.\\n\\nDavid Feng\\nProductions preferred solution.\\n\\nAiken, David\\nYeah.\\n\\nAiken, David\\nIt it it, it gets around after does for sure.\\n\\nAiken, David\\nAnd we have a lot of customers use Oct you know for for that.\\n\\nAiken, David\\nYeah. So, OK.\\n\\nAiken, David\\nUmm so.\\n\\nAiken, David\\nAnd he on on the code ocean side. Any kind of specific things that might\\ncatch us out here like is then you you mentioned some specific\\nrequirements that maybe discounted using like the age of Los Directory\\nservice. She said there was a missing API.\\n\\nDavid Feng\\nYeah, there's no way that I could see.\\n\\nDavid Feng\\nFor the AWS Identity Center to push user groups into a third party\\napplication.\\n\\nAiken, David\\nRight.\\n\\nAiken, David\\nI'm not gonna use that.\\n\\nAiken, David\\nYeah.\\n\\nAiken, David\\nYeah, cause kind of the the almost the design point for identity senders\\nto be the other side of that relationship, right? So that you federate\\nwith something and we have a kind of lightweight directory service in\\ncase you don't have one, right. But you know if I'm thinking about some\\nof the customers I work with where you know they have like the typical\\napplications, right teams, Office 365 you know they have like.\\n\\nAiken, David\\nSome off the shelf of the kind of applications hosted they're using some\\nSAS services. You know, they're they're more likely to be the using.\\n\\nAiken, David\\nRealistically, either Azure AD or Octa are the two big ones that we we\\ncome across there right mostly, you know in the has been around for\\ndonkeys years in Windows and it's just an evolution there, right. And\\nthe full disclaimer I used to work at Microsoft and.\\n\\nAiken, David\\nUh.\\n\\nAiken, David\\nMight Nelson things about the Azure AD and why they build it and all\\nthat kind of thing? So it's the perfect scenario for for this.\\n\\nAiken, David\\nI think we should go kind of do some due diligence around looking at\\ncognito.\\n\\nAiken, David\\nAnd Octa as well, but you still end up, you know, you, you, you still\\nhave your D.\\n\\nAiken, David\\nYou're you're Federated with Azure AD already.\\n\\nAiken, David\\nWe'd need a real compelling reason to go switch to something.\\n\\nDavid Feng\\nI I can tell you.\\n\\nAiken, David\\nYou know across across the board.\\n\\nDavid Feng\\nSo I'll tell you where.\\n\\nAiken, David\\nYeah.\\n\\nDavid Feng\\nI was originally planning just to use our existing AD tenant and I was\\nwaved off because they said no way to bring in other domains like you\\ndub. No, cannot add users and and I'm not allowed to self manage my\\npolicy the Institute. So then I'm just gonna and they they told me to go\\naway so.\\n\\nAiken, David\\nGood, good answer to them.\\n\\nDavid Feng\\nYeah.\\n\\nRob Young\\nBut.\\n\\nAiken, David\\nYeah.\\n\\nDavid Feng\\nSo this is before I learned about Rob's whatever Azure AD B2C with a lot\\nof stuff letters. So if that's an option, I can do that. I honestly\\ndon't care. I just want a solution the worst.\\n\\nAiken, David\\nYeah. And and I saw Ashmeet jumped on.\\n\\nRob Young\\nAlright.\\n\\nAiken, David\\nSo maybe I can spend just 30 seconds catching up if that works for you\\nashmeet.\\n\\nAWS - Ashmeet Pahwa\\nYeah, definitely.\\n\\nAiken, David\\nOK. Can you see my screen?\\n\\nAWS - Ashmeet Pahwa\\nHave five, so apologize. I've been in and out of the appointment. I'm\\nstill at the doctor's office, so.\\n\\nAWS - Ashmeet Pahwa\\nBut yeah, definitely go ahead.\\n\\nAiken, David\\nWhy? Why are you on this call?\\n\\nAWS - Ashmeet Pahwa\\nOhh well, I'm sitting in the lobby now.\\n\\nAWS - Ashmeet Pahwa\\nYeah.\\n\\nAiken, David\\nOK. Well, just if you suddenly hang up because you've had to go do\\nsomething more important, we understand. So don't bother, you know.\\n\\nAWS - Ashmeet Pahwa\\nThank you.\\n\\nAiken, David\\nWaiting for a gap. Just hang up. We know where you're, uh. OK, so um, so\\nwe've got we've got this code option which is an application and we've\\ngot other apps.\\n\\nAiken, David\\nAnd we've got all these different users. So we've got kind of like they\\ndo we Allen Institute.\\n\\nAiken, David\\nIt AWS people like Rob Shin like kind of person. We've got the\\nalleninstitute data scientists. We've got some UW data scientists and\\nmaybe other organizations, right? So the universities, the kind of\\nresearch institutes, that kind of thing. And then we've got this kind of\\nopen platform for creating IDs and authenticating think of like.\\n\\nAWS - Ashmeet Pahwa\\nUmm.\\n\\nAiken, David\\nYou know using Google as your identity provider but with a little bit\\nmore metadata tuned to data scientists, right? It's still, you know,\\nit's not like.\\n\\nAWS - Ashmeet Pahwa\\nGot it.\\n\\nAiken, David\\nThe Amazon directory where you have to be employed, anybody can get an\\naccount there. So what we're trying to do is figure out like we've got\\nall these this three groups.\\n\\nAiken, David\\nOf of targets.\\n\\nAiken, David\\nIs there a single where we can kind of collaborate across these\\ndifferent identity providers, right? So we're kind of looking at.\\n\\nAiken, David\\nLike Rob's already and the data scientist, you know, if you employed by\\nthe Allen Institute, you have an account in the Allen Institute\\nDirectory service, Great Udub, Stanford, MIT, whatever you've got it.\\nProbably a directory that you're already associated with, right?\\n\\nAWS - Ashmeet Pahwa\\nYes.\\n\\nAWS - Ashmeet Pahwa\\nSo.\\n\\nAWS - Ashmeet Pahwa\\nQuick question.\\n\\nAiken, David\\nUm this I could probably create an account here and get away with it, so\\num, but is there a? Is there a place where we can federate all these so\\nthat we're just code ocean just federates with one thing and not the\\nmultiple things. So there's kind of this layer in between. So that's\\nwhat we're trying to figure out what the solution is there, whether it's\\nAzure AD or COGNITO or October or some other Cyberark, whatever. Yeah.\\n\\nAWS - Ashmeet Pahwa\\nQuick question, where how does uh code ocean?\\n\\nAWS - Ashmeet Pahwa\\nAnd I, you know, I was, I was hearing some of the things in the in the\\nmeeting. But could you give me like a quick overview how what's what's\\nthe use of code of code ocean here and how is it allowing access like\\ndoes it have its own resources in a separate obvious account or does it\\nneed?\\n\\nAWS - Ashmeet Pahwa\\nFederated users from the current organization that we have allowed them\\naccess to go into code ocean and spin up resources.\\n\\nAWS - Ashmeet Pahwa\\nOK.\\n\\nDavid Feng\\nSo let me try to answer your questions briefly. The code code motion is\\nan application that runs in AWS, so it's all AWS services.\\n\\nDavid Feng\\nIt's got. I don't know exactly what technology it uses, but it's got\\ninternal and internal lightweight user database.\\n\\nDavid Feng\\nUh.\\n\\nDavid Feng\\nAnd who knows what that is. They when you want to start doing group\\nlevel permissions they say please please use an identity management\\nsolution instead and so there they'll authenticate with any ID or.\\n\\nDavid Feng\\nSaml 2 identity management providers provided that provider is able to\\npush users and user groups down.\\n\\nAWS - Ashmeet Pahwa\\nGotcha. So it's it's basically it's basically kind of like a service\\nprovider rather than an identity provider which can take an external\\nidentity and provide access, yeah.\\n\\nAWS - Ashmeet Pahwa\\nWell.\\n\\nDavid Feng\\nThat's right. And so that, you know, they they have this lightweight\\nthing, if you if you don't want to get an identity provider, but it\\nwe're we're just now getting to the point where I think we need to take\\nseriously doing something not lightweight, in which case they'll they'll\\nrelinquish control to a third party identity management solution.\\n\\nAWS - Ashmeet Pahwa\\nGot it.\\n\\nAWS - Ashmeet Pahwa\\nOK.\\n\\nRob Young\\nSo just to clear a couple of things that might be of interest or just\\nadd some additional color to that. So when we were talking about the.\\n\\nRob Young\\nThe Azure AD for for identities of Allen Institute employees.\\n\\nRob Young\\nThey have a tenant in Azure AD that that is limited to the yeah. Allen\\ninstitute.\\n\\nAWS - Ashmeet Pahwa\\nOK.\\n\\nAWS - Ashmeet Pahwa\\nMm-hmm.\\n\\nRob Young\\nWe have created a second tenant that is an Azure B2C type of tenant that\\nallows us to do that support for Federated you know identity providers\\nand then we are creating groups and roles in that B2C tenant.\\n\\nRob Young\\nThat we're using in support of our our services today for the platform\\nservices.\\n\\nAWS - Ashmeet Pahwa\\nHi.\\n\\nRob Young\\nThe question you know the the the reason why we were here that I'm here\\ntoday. I wanted to talk about this was do we want to just can we find an\\nAWS product to take the place of that B2C tenant so that we have better.\\n\\nRob Young\\nAre we're closer to the resources we're restricting access to?\\n\\nRob Young\\nAnd and, and hopefully simplifying our management. And then the issue\\nwe're having is identity center has looked like it would probably do\\nwhat we want it to do. But apparently identity center does not support\\npushing groups.\\n\\nRob Young\\nTo code ocean with its with its skim support so that so yeah, so it was\\nthere, yeah.\\n\\nAWS - Ashmeet Pahwa\\nThat is correct. Yeah, that is correct. It it only has the, it only has\\ninbound schemas and have outbound there, correct? Yeah.\\n\\nRob Young\\nOK, so so does cognito have outbound scan?\\n\\nRob Young\\nOK.\\n\\nAWS - Ashmeet Pahwa\\nOhh no so you. So for outbound scam the way it would work is they're\\ngonna have to do some custom logic to basically you know when the user\\nis authenticated or to take the user attributes from cognito user pool\\nand then push it out. But that's.\\n\\nAWS - Ashmeet Pahwa\\nThat's gonna be a complex logic. We might have to do some testing on\\nthat. I personally haven't tested that out, so I can't say to it, but\\nthere might be ways to do it.\\n\\nAWS - Ashmeet Pahwa\\nCan you guys hear me?\\n\\nAiken, David\\nYep.\\n\\nAWS - Ashmeet Pahwa\\nAlright, perfect. Yeah.\\n\\nAWS - Ashmeet Pahwa\\nI would.\\n\\nAWS - Ashmeet Pahwa\\nSuper cold ocean. Can we do something like and you know, just throwing\\nout ideas here. So does code ocean integrate with Azure AD?\\n\\nAiken, David\\nYeah.\\n\\nDavid Feng\\nIf it does.\\n\\nAWS - Ashmeet Pahwa\\nOK, OK. And can we explore something like user replication in Azure AD?\\nSo what we can essentially do is so.\\n\\nAWS - Ashmeet Pahwa\\nFor identity center you create a application an enterprise application\\nin Azure AD from where your users and groups are, you know, provisioned\\ninto AWS via scam to .0.\\n\\nAWS - Ashmeet Pahwa\\nWhat if you create some, you know a group separately for code ocean as\\nwell and kind of do a replication based on group name.\\n\\nAWS - Ashmeet Pahwa\\nBetween two separate uh enterprise applications on Azure AD site might\\nrequire a custom custom script to do that, but we could do something\\nlike that.\\n\\nDavid Feng\\nRight.\\n\\nAWS - Ashmeet Pahwa\\nAnd it's just a it's just a high level idea right now. I'm not. You\\nknow, I'm not trying to solution here, but.\\n\\nDavid Feng\\nThat that seems good.\\n\\nRob Young\\nI'm curious, asked me, why do why do we? We need to separate group for\\ncode ocean.\\n\\nAWS - Ashmeet Pahwa\\nBecause how would you use the same you know same enterprise application\\nfor two separate? You know basically service providers because you're\\nyou're establishing a trust between identity center and the enterprise\\napplication.\\n\\nAWS - Ashmeet Pahwa\\nSo you could there's a certificate installed.\\n\\nAWS - Ashmeet Pahwa\\nAnd then there's a skim token that that is being, you know, it's\\nbasically established, establishing his trust between the Azure AD and\\nAWS. So for to do that in.\\n\\nAWS - Ashmeet Pahwa\\nOf a code ocean. You're gonna have to have unique certificate and skim\\ntoken. That's the reason we might need another group.\\n\\nAWS - Ashmeet Pahwa\\nUmm.\\n\\nAWS - Ashmeet Pahwa\\nUh-huh.\\n\\nRob Young\\nI OK, I'm I could do some research on that. I think we're we have\\nmultiple enterprise applications registered in that B2C tenant by the\\nway, it's B2CE as in like like consumer for some reason I don't know why\\nthey call it B2C David, but it's not to be to be.\\n\\nAiken, David\\nOK.\\n\\nRob Young\\nLike he is in Charlie but.\\n\\nRob Young\\nYeah, we are using. We are defining groups and then using those groups\\nacross enterprise registered apps, enterprise apps. So I'm I think we\\nmay be able to do that, but regardless.\\n\\nRob Young\\nJust to summarize what I think you were suggesting we consider would be\\nsomething where we're using the B2C tenant as kind of our.\\n\\nRob Young\\nOur resource of record or service of record for these you know for\\nmanaging these identity to group assignments and then we're registering\\ncode ocean to Azure, but we're also setting up.\\n\\nRob Young\\nSkim.\\n\\nRob Young\\nOutbound from Azure into Identity Center in AWS so that we can have one\\nplace where we manage these identities to group assignments and we're\\nsupporting code ocean and then we're also getting it into AWS so we can\\nmanage resources in AWS as well. Is that the suggestion?\\n\\nAWS - Ashmeet Pahwa\\nCorrect. Correct. Yeah.\\n\\nAWS - Ashmeet Pahwa\\nAnd you know, I mean cause again you you, you know, I might need to have\\na separate conversation. And then I I can look more into it now that I\\nknow a little bit of a better picture on what what all is included.\\n\\nAWS - Ashmeet Pahwa\\nAnd I can do some research on that, but this is this is one of the\\nthings that I came up with right now, but might have to look into it for\\nsure.\\n\\nDavid Feng\\nIt seems like a rational solution to me, so I think just homework for me\\nis to confirm that specifically Azure AD B2C plays nice with code ocean\\nand I've I've had trouble with certain certain authentication solutions\\nthat didn't, so I'll let me let me try it and confirm. And if it does\\nthen.\\n\\nDavid Feng\\nGreat.\\n\\nTim Dolbeare\\nI'm satisfied when Rob and David are satisfied.\\n\\nRob Young\\nWell, and and I think the key there is also that we're set that they're\\nboth satisfied about the same thing and not enough satisfied, but moving\\nin different directions. OK, well, thank thank you for that suggestion,\\nI guess. So in this in this scenario.\\n\\nRob Young\\nIf, if we are pushing those.\\n\\nRob Young\\nWe can push those groups and identities these users into AWS Identity\\nCenter.\\n\\nRob Young\\nSo then.\\n\\nRob Young\\nOK. And that's and then?\\n\\nRob Young\\nAre we done talking? Do you think that's enough to talk about the code\\nocean use case, David and Tim?\\n\\nRob Young\\nFor for now.\\n\\nDavid Feng\\nI'm good.\\n\\nRob Young\\nOK. Because then, because I would, I'd like to segue into the use case\\nof, OK we have.\\n\\nRob Young\\nWe have a service, but it's one of those enterprise applications\\nregistered with the B2C tenant that is or at least currently that is.\\n\\nRob Young\\nThat's going in. This doesn't exist yet. We're developing it. It's\\ngonna. It's gonna be just a list of projects, and we're going to be\\nassociating users to to studies or projects with a role.\\n\\nRob Young\\nAnd then we want to be able to.\\n\\nRob Young\\nTo to use that to authorize access to data in databases across multiple\\nservices, and we're tracking those those associations to that project\\nacross multiple services and then also.\\n\\nRob Young\\nUm restrict access to specific AWS resources like S3 buckets.\\n\\nRob Young\\nAnd does that is that does that use case first of all, do you have\\nquestions about that use case or does it make sense?\\n\\nAiken, David\\nI think it makes sense, but so are we. So how you're thinking about\\nhandling the permissions? Is this something that the app is gonna have\\nlogic to do based on the identity of the user? Or is it something you're\\nexpecting the platform to do magically?\\n\\nRob Young\\nI'm. I'm expecting that we'll have to have logic that's filtering data\\nthat we return it it's it's that's that's part of the.\\n\\nRob Young\\nIt's it's, it's in our, our, our our data layer.\\n\\nRob Young\\nAnd as filtering out data they don't have, they're not authorized to\\naccess. But then I'm also looking for some way for us to automate so\\nthis could even just be something where we have infrastructure as code\\nor something that when someone creates that association between a user a\\nproject and assigns a role to that edge between them.\\n\\nAiken, David\\nRight.\\n\\nRob Young\\nThat we could then create an explicit role for that project.\\n\\nRob Young\\nAnd then apply it. You know, get that user that the appropriate\\npermissions so that.\\n\\nRob Young\\nFor example, they can they can access a bucket and actually write to it,\\nor read, you know, etcetera.\\n\\nAiken, David\\nRight.\\n\\nAWS - Ashmeet Pahwa\\nI'm gonna do. I'm gonna if you wanna go a little more granular, I think\\nyou can also do attribute based access control and use tags instead.\\n\\nRob Young\\nMm-hmm.\\n\\nAWS - Ashmeet Pahwa\\nUm, having the same role, but then permission policies itself will\\nidentify because you know your request is coming through a similar\\nassertion anyways, so the attribute that you're passing in your request\\nhas got is gonna be there.\\n\\nAWS - Ashmeet Pahwa\\nSomeone assertion. So when the request comes in cloud trail or whatever\\nservice you use, you know it it'll identify.\\n\\nRob Young\\nRight.\\n\\nRob Young\\nOK.\\n\\nAWS - Ashmeet Pahwa\\nThe the the attributes as tags in the request and use that and you\\npolicies.\\n\\nRob Young\\nSo, so one concern we had is the JWT coming back from.\\n\\nRob Young\\nAzure is is going to have. It does have a a limit on size.\\n\\nAWS - Ashmeet Pahwa\\nUmm.\\n\\nRob Young\\nAnd given that we have N number of projects and I'm I was just wondering\\nif there's.\\n\\nRob Young\\nIf that's, I'm wondering, I forget what the actual size limit is, but\\nthere is a limit to the size of the JSON document.\\n\\nRob Young\\nThat.\\n\\nAWS - Ashmeet Pahwa\\nTurn left on.\\n\\nRob Young\\nThat gets encrypted and I'm wondering if if.\\n\\nRob Young\\nAnd you know, maybe we we.\\n\\nRob Young\\nUnder there's just there's so many projects and there are so many\\nscientists who are have relationships with multiple projects.\\n\\nRob Young\\nAnd it would have roles in.\\n\\nRob Young\\nYeah, a lot of projects. I mean we could, I I I don't know. I guess we\\ncould potentially have some if they are something where they're gonna\\nhave access to everything. They just have have a a power user kind of.\\n\\nRob Young\\nUh role for Allen Institute data. But I'm just, I guess I'm just\\nwondering if that.\\n\\nRob Young\\nIf there are any other options, even if we definitely can explore that.\\n\\nAiken, David\\nSo you've got multiple.\\n\\nAiken, David\\nSo you got multiple projects.\\n\\nAiken, David\\nRight.\\n\\nAiken, David\\nOhh, and then you've got.\\n\\nAiken, David\\nUse a.\\n\\nAiken, David\\nHe belongs anger. I will find the group said so. Reuser belongs to a\\ngroup.\\n\\nAiken, David\\nAnd then that group could.\\n\\nAiken, David\\nBelong to a project or a bunch of projects.\\n\\nAiken, David\\nAnd that group would have a set of permissions I guess. So there's a\\nmiddle.\\n\\nAiken, David\\nSo you've got group creation.\\n\\nTim Dolbeare\\nYeah, I mean, you can think of it as like each application might be\\npretty simple, right? They might have a reader and.\\n\\nTim Dolbeare\\nService role and an admin role, but then all of those need to be fully\\nqualified with.\\n\\nTim Dolbeare\\nOr what project?\\n\\nAiken, David\\nRight.\\n\\nTim Dolbeare\\nAnd so you know, you get a cell service all times 3 roles and you get.\\n\\nTim Dolbeare\\nThat's service times 3 rolls, and so on.\\n\\nTim Dolbeare\\nSo they could add up pretty quickly.\\n\\nAiken, David\\nRight.\\n\\nRob Young\\nSo well, I was actually thinking of.\\n\\nRob Young\\nSteven in in terms of the mapping, it would be like the the project\\nwould represent a study, so it would be something like the macaque Atlas\\nfor merscope. But you don't have access to the human Atlas from Merscope\\nor the Mouse Atlas, but you have maybe you have read only access to\\nthose, but you have write access to the macaque one because that's when\\nyou're working on our rewrite. And so.\\n\\nRob Young\\nUm.\\n\\nRob Young\\nThat's where it gets messy.\\n\\nAiken, David\\nSo are we. Are we talking like so using that use case there? Right. You\\nsaid there's A and then you said words and I can't remember now, but\\nthere was a there was a something.\\n\\nAiken, David\\nYeah.\\n\\nTim Dolbeare\\nMcat.\\n\\nAiken, David\\nWhat was that?\\n\\nRob Young\\nOhh macaque, it's and it's it's non human primate. It's a monkey.\\n\\nAiken, David\\nOK, so non human primate. And then there was like.\\n\\nRob Young\\nMouse.\\n\\nAiken, David\\nMouse and then something else? Or is it just like there's a database?\\n\\nAiken, David\\nAnd like.\\n\\nRob Young\\nWell.\\n\\nRob Young\\nThen we would, yeah.\\n\\nAiken, David\\nBoth of these live inside that one database or 1S3 budget. Now you're\\ntrying to say, hey, Billy, because he belongs to Project Air can only I\\ncan read this but can write maps. And he also belongs to Project B,\\nwhich means he can read mouse and read.\\n\\nAiken, David\\nNon human primate.\\n\\nAiken, David\\nRight.\\n\\nAiken, David\\nRight.\\n\\nRob Young\\nRight. So in that scenario the database we contain details regarding\\nboth and we'd be having association to the project that we would be\\nusing to filter the data that gets returned potentially. And then\\ninstead inside the database there be application logic or data layer\\nlogic and then we would have separate buckets for each project's data on\\nS3 which would have its own restrictions based on their project.\\n\\nRob Young\\nUh.\\n\\nRob Young\\nRole.\\n\\nAiken, David\\nRight.\\n\\nRob Young\\nOr accessed or just roll to that in in you know.\\n\\nRob Young\\nYeah.\\n\\nTim Dolbeare\\nYeah, that gets messy, rob. I mean, there's some data that is.\\n\\nTim Dolbeare\\nUsed in multiple projects.\\n\\nRob Young\\nIt's true and.\\n\\nRob Young\\nAnd it's really it's. It's just how do we.\\n\\nRob Young\\nHow you know?\\n\\nRob Young\\nAnd there there will be the case. But if you have access to any of those\\nprojects, you would have access to that thing.\\n\\nRob Young\\nIn theory.\\n\\nRob Young\\nWhichever bucket it was placed in.\\n\\nAiken, David\\nSo if can you have access to a project as like a read only or a write\\nlike.\\n\\nRob Young\\nRight.\\n\\nAiken, David\\nIf you think about like some of the like, I don't Google, Google does\\nthis or or like Dropbox, but you have like a the the owner of the thing\\nyou have like a contributor. You have a reader, so you've got like this\\nvery high level set of permissions. So we think in the same type of\\nthing for each project. So project they would have like an admin owner,\\ncontributor and a reader.\\n\\nAiken, David\\nAnd then Billy could. Could Billy could belonged the project as a as a\\nreader, but Project B, he's the admin.\\n\\nAiken, David\\nOK.\\n\\nRob Young\\nCorrect. That's you can think of it that way, yes.\\n\\nAiken, David\\nAnd and is there like Super fine grained things here or is it like super\\nbroad like?\\n\\nRob Young\\nIt's pretty broad in that.\\n\\nRob Young\\nYou mentioned admin and.\\n\\nRob Young\\nThat would only come typically they would not. We probably wouldn't even\\neven if it was just read and read write.\\n\\nRob Young\\nAnd then I could see it's also having additional permissions for things\\nlike.\\n\\nAiken, David\\nRight.\\n\\nRob Young\\nAble to run workflows, you know EC2 and stuff like that at some point,\\nbut but at least you know for this use case it's really just like the\\nread and you know if can you read it, can you read and write?\\n\\nRob Young\\nUh, and then maybe even another one for the ability to delete like a\\npower user.\\n\\nAiken, David\\nRight.\\n\\nAiken, David\\nYeah. So there's like a, we'll call it, owner.\\n\\nRob Young\\nMm-hmm.\\n\\nAiken, David\\nI want a better thing, and then you've got kinda like.\\n\\nRob Young\\nAnd.\\n\\nAiken, David\\nAnd I'm, I'm and then we've got a kind of a a viewer.\\n\\nRob Young\\nYep.\\n\\nAiken, David\\nKind of thing.\\n\\nAiken, David\\nOK.\\n\\nAiken, David\\nOhh dear.\\n\\nAiken, David\\nBecause then your application logic's gonna do something like you know.\\n\\nAiken, David\\nOld and Dirty sequel, right? They'll be like select star from Doodah\\nwhere project equals project there.\\n\\nAiken, David\\nAnd the updates only gonna work if you're the the user is a contributor\\nor an owner like so you you you've got some very basic.\\n\\nAiken, David\\nUm.\\n\\nRob Young\\nCrud stuff.\\n\\nAiken, David\\nYeah, to to work with, right?\\n\\nRob Young\\nUmm.\\n\\nAiken, David\\nBut, but that's still gonna need to be like application level stuff\\nthere, right? When when you get the S3 budget, it could then be an and\\nit depends on how we're gonna let them access the three budget, right?\\nSo are they gonna be able to just.\\n\\nAiken, David\\nAccess it anytime like they're they're just, but more than likely\\nthey're gonna need to refresh some creds, right? So.\\n\\nRob Young\\nRight.\\n\\nAiken, David\\nWe're not gonna give them a secret key and access key. Perhaps like we\\ndo today. That lasts forever. We're gonna give them some temporary\\ncredentials.\\n\\nRob Young\\nRight.\\n\\nAiken, David\\nSo which so that maybe in the app there's a way to issue them those\\ncredentials so they can run CLI commands or give them console access\\nwith with a restricted thing?\\n\\nAiken, David\\nI don't know the the like putting stuff in the nursery budget without\\nany identity is.\\n\\nAiken, David\\nIt can be easy or hard depending on your outlook on life, so you know we\\ncan generate.\\n\\nAiken, David\\nSigned URL's to allow them temporary access to things.\\n\\nRob Young\\nOK.\\n\\nAiken, David\\nSo there we go into the app and then they would get like a signed URL\\nand then they could go do things with it. But it depends on the workflow\\nhow useful that is. So if it's like application code doing it, it's\\nreally easy for an application to go hey, give me a URL, give me a\\nsigned URL.\\n\\nAiken, David\\nAnd then get assigned URL and then use that signed URL to put objects\\nthere or read objects or do whatever humans don't tend to do well with\\neight feet long URLs, right?\\n\\nRob Young\\nSo.\\n\\nRob Young\\nRight.\\n\\nAiken, David\\nSo that that could be something that we need to think about that on how,\\nhow, how are we given Barb access to the S3 budget in, in the app. And I\\nknow today you're giving them I am accounts, but we might wanna stop\\nthat.\\n\\nRob Young\\nYes, so.\\n\\nRob Young\\nOne thing we have, and so just to give you an idea of how we're\\npopulating this for, for production purposes there would be we and we've\\njust started kind of.\\n\\nRob Young\\nDuring this development.\\n\\nAiken, David\\nYeah.\\n\\nAiken, David\\nOK.\\n\\nRob Young\\nOr we're nearing actually in production version of this, where there's a\\nservice account. In other words, they go in and within the database\\naccount they create an IAM user for a service that is this going to\\ntransfer files and it gets a secret key and we're managing that in\\nAdobos sequence manager and we've got a Python library that will has\\nbeen written to go and get that key and then use that to access the\\nbucket and write files there or get files from there. And we have\\nanother service that keeps track of the URLs to those files.\\n\\nRob Young\\nAnd they can and it's associated with the experiment, and they can\\nbasically go through our API and it handles that for them. That's one\\nway that this would work.\\n\\nRob Young\\nWith the scientists are going to go directly to the buckets too. I mean,\\nthat's just not gonna wanna do this most the time.\\n\\nRob Young\\nYeah.\\n\\nAiken, David\\nYeah, I know you wanted to do Edu S3 CP. He's a bunch of star. He's a\\nbunch of files. Go upload them, right?\\n\\nAiken, David\\nUm.\\n\\nRob Young\\nYeah. And so there's that too.\\n\\nAiken, David\\nOK.\\n\\nTim Dolbeare\\nYeah.\\n\\nRob Young\\nBut we are we are planning to have them.\\n\\nRob Young\\nProvisioned buckets for specific studies and then you know, assign.\\n\\nRob Young\\nAnd sign and basically manage the resource access to those resources\\nbased on it that that study level or project level.\\n\\nAiken, David\\nRight.\\n\\nRob Young\\nAnd so that's where it gets it gets a little I would love to see if.\\n\\nRob Young\\nIf we can just figure out a way to automate.\\n\\nRob Young\\nThat connection between you know, that association between the user and\\nthese projects that we're managing in a database.\\n\\nRob Young\\nAnd find a way to.\\n\\nAiken, David\\nRight.\\n\\nAiken, David\\nYeah.\\n\\nRob Young\\nTo automate how we register those with identity center or whatever we're\\nusing and then use that to assign those resources or access to the S3\\nbuckets or whatever else, and that that's what I'm wondering about. Is\\nthere a way for us to automate that so that it's so that we have a high\\nlikelihood that they're In Sync?\\n\\nAiken, David\\nRight.\\n\\nRob Young\\nThey don't, and it doesn't require my time to make it happen.\\n\\nAiken, David\\nYeah, I've, I've.\\n\\nTim Dolbeare\\nIt would be great if we could provide a abstraction layer that.\\n\\nRob Young\\nYeah.\\n\\nTim Dolbeare\\nMade it look like a file system because our scientists honestly don't\\nwant to deal with S3 buckets because they don't. They're not familiar\\nwith it, so if we could have some kind of application that made it look\\nlike a file system.\\n\\nTim Dolbeare\\nAnd manage the.\\n\\nRob Young\\nThe.\\n\\nTim Dolbeare\\nManage the permissions at that layer.\\n\\nRob Young\\nThere's a there's a service called nasuni.\\n\\nRob Young\\nThat all works with AWS and also with POSIX compliant Linux and EQUATE.\\nIt creates like a virtual.\\n\\nRob Young\\nUh POSIX compliant file system that includes your object storage.\\n\\nAiken, David\\nRight, yeah.\\n\\nRob Young\\nThat's one option. We and and they've been spamming me trying to get me\\nto set up a meeting. David David Feng was was actually talking to them.\\n\\nRob Young\\nUmm so that that is an option. It's just yet another service we'd have\\nto pay for.\\n\\nTim Dolbeare\\nYep.\\n\\nAWS - Ashmeet Pahwa\\nSo 111.\\n\\nAiken, David\\nYeah, there's a couple of different ways of doing the same thing. Yeah.\\nSorry, ashmeet.\\n\\nAWS - Ashmeet Pahwa\\nYeah. No, that's OK. Go ahead. I I just wanted to say there's one other\\nidea, if you haven't looked into, but there's a AWS transfer family if\\nyou want to look into it's kind of like an SFTP server. You connect it\\nto an S3 bucket and it gives you lists, you files like an asset, TV\\nserver and you can use use any open source SFTP client to connect to it\\nusing SSH keys or IM users. That's also something something that can be\\nutilized or looked into.\\n\\nRob Young\\nAnd just look for AWS FTP or is there? Is there a a clever name for the\\nthe project or?\\n\\nAWS - Ashmeet Pahwa\\nOhh.\\n\\nAiken, David\\nYeah.\\n\\nAWS - Ashmeet Pahwa\\nYeah. I mean, the name of the service is transfer family.\\n\\nRob Young\\nTransfer family.\\n\\nAWS - Ashmeet Pahwa\\nYeah, AWS transfer family.\\n\\nRob Young\\nOK. Thank you.\\n\\nAWS - Ashmeet Pahwa\\nUh, as far as I remember, cause it's been some time that I looked into\\nit, but I've used it in the past.\\n\\nAWS - Ashmeet Pahwa\\nIt it it'll basically create a server for your S3 bucket.\\n\\nAWS - Ashmeet Pahwa\\nYou, you, you provision, you enable the service, you connect it to a\\nspecific bucket, multiple buckets. You can do that and it'll basically\\ncreate an SFTP server for that specific bucket where you can based on\\nthe access that you provide it'll work like a normal SFTP client which\\nany normal SFTP client you can connect with it and.\\n\\nAWS - Ashmeet Pahwa\\nUh at least files just like a SFTP server.\\n\\nRob Young\\nOK. Thank you for that recommendation. We'll check it out. I think we're\\nout of time.\\n\\nRob Young\\nBut I think we've at least covered the use cases now, maybe.\\n\\nAiken, David\\nI.\\n\\nRob Young\\nDid you have any other questions for me, David or Ashmeet? Thank you for\\nagain, for, for meeting with us by the way.\\n\\nAiken, David\\nYeah. And any any time. So I think I'd like to have a huddle with\\nAshmeet and Mike and.\\n\\nAiken, David\\nKind of brainstorm a couple ideas and then kind of come back with a\\ncouple of proposals or designs or more questions more likely.\\n\\nRob Young\\nOK.\\n\\nAWS - Ashmeet Pahwa\\nYeah, we're questions like.\\n\\nAiken, David\\nAnd then we'll kind of keep chipping away at it. Yeah, I'm. I'm sure\\nwe'll have more questions. Yeah. Cool. This has been great. Robin.\\nThanks for getting Dave or David on on the code ocean thing. So.\\n\\nAiken, David\\nGood stuff.\\n\\nAiken, David\\nYeah.\\n\\nAiken, David\\nYeah, yeah, yeah.\\n\\nRob Young\\nDavid. John. He he dropped a while ago, but I'll. I'll, I'll, I'll let\\nhim know and and and have a great weekend. Happy Friday and look forward\\nto to whatever you can come up with. Certainly appreciate you. You you\\nare considering the the challenge we're trying to overcome and and\\nyou're any help would be much appreciated.\\n\\nAiken, David\\nAwesome.\\n\\nAiken, David\\nLikewise, have a great weekend Rob and Chen, and talk to you all on\\nMonday. Sure.\\n\\nShane Vance\\nYeah. Thank you.\\n\\nRob Young\\nAll right. Thank you all very much.\\n\\nAWS - Ashmeet Pahwa\\nYep.\\n\\nAWS - Ashmeet Pahwa\\nTalk to you. Bye bye.\\n\\nRob Young\\nAnd hope hope all is well. Bye.\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf269827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSummary: David Feng is looking for a way to use AWS Identity Center to push user groups to a third party service, Code Ocean, which allows scientists to do analysis on data in the cloud. Rob Young suggested that Cognito might be an option to enable the pushing of user groups, and Tim Dolbeare mentioned that he needs to be able to share with collaborators and partition access to resources within the cloud. Aiken David suggested that access to Code Ocean doesn't necessarily mean giving access to an S3 bucket, and all access is controlled by the app.\\n\\nIn this meeting, the participants discussed the budget in the app, the ability to access plain vanilla S3 buckets, the need for an authenticator, and the need for an identity provider. They also discussed the issue of David's screen not being visible and the need to reset it.\\n\\nDavid Feng and Rob Young discussed the challenge of controlling access to their apps and data. They discussed the possibility of using Azure AD to manage access, as well as the possibility of using Orchid as an identity provider. They also discussed the possibility of federating with larger institutions to allow access to their apps and data.\\n\\nDavid Feng and Rob Young discussed the need for a single identity provider that could collaborate across different identity providers, such as Azure AD, COGNITO, and Octa. They discussed the possibility of using Azure AD B2C, but were looking for a more lightweight solution. AWS - Ashmeet Pahwa joined the conversation and asked for an overview of how Code Ocean works and how it allows access. David Feng explained that Code Ocean is an application that runs in AWS and has an internal lightweight user database. They discussed the possibility of using Azure AD for Allen Institute employees, and creating a second tenant that is an Azure B2C type of tenant to support Federated identity providers. The goal was to find an AWS product to take the place of the B2C tenant to simplify management and restrict access. However, they found that Identity Center does not support pushing groups to Code Ocean.\\n\\nSummary: The meeting transcript discussed a use case where a service is being developed that will associate users to projects with a role. The group discussed the possibility of using Azure AD B2C tenant as a resource of record for managing identities and groups, and setting up outbound skim token from Azure to AWS Identity Center. They also discussed the possibility of using attribute based access control and tags in the request to identify attributes in the request. They discussed the potential size limit of the JSON document that gets encrypted, and the possibility of having a power user role for Allen Institute data.\\n\\nDavid Feng and the other speakers discussed the need for an API to manage access to data stored in an S3 bucket. They discussed the need for different levels of access, such as read-only, read-write, and delete, and how to manage access to the S3 bucket. They also discussed the need for a service account to manage access to the bucket, and the need for a Python library to get the secret key and access the bucket. Finally, they discussed the need for a service to keep track of URLs to the files stored in the bucket.\\n\\nAt the meeting, Rob Young discussed the need to automate the connection between users and projects managed in a database, and the need to assign resources or access to S3 buckets. Ashmeet Pahwa suggested looking into AWS Transfer Family, which is an SFTP server that connects to an S3 bucket and provides a file system-like interface. David Aiken suggested having a huddle with Ashmeet and Mike to brainstorm ideas and come up with proposals or designs. The meeting concluded with everyone agreeing to talk again on Monday.\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile = '/home/tim/work/projects/transcripts/AWS_LZ_Fun_Time_2023-02-10.docx'\n",
    "outfile = '/home/tim/work/projects/transcripts/AWS_LZ_Fun_Time_2023-02-10.txt'\n",
    "CodeOceanAndAWSOPS_2023-02-15\n",
    "\n",
    "#transcript_file = word_to_text(infile, outfile)\n",
    "\n",
    "transcript_file = '/home/tim/work/projects/transcripts/AWS_LZ_Fun_Time_2023-02-10.txt'\n",
    "\n",
    "raw_transcript = load_transcript(transcript_file)\n",
    "preprocessed = preprocess_transcript(raw_transcript)\n",
    "chunks = chunk_text(preprocessed, chunk_size=100)\n",
    "\n",
    "#len(chunks)\n",
    "\n",
    "sub_sums = summarize_chunks(chunks, prompt='summary', max_tokens=900)\n",
    "sub_sums\n",
    "print(sub_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e09dcbbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m final \u001b[38;5;241m=\u001b[39m \u001b[43msummarize_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_sums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msuper_sum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m900\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(final)\n",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m, in \u001b[0;36msummarize_chunks\u001b[0;34m(chunks, prompt, max_tokens)\u001b[0m\n\u001b[1;32m      2\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[0;32m----> 4\u001b[0m     r \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43msubmit_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m, in \u001b[0;36msubmit_prompt\u001b[0;34m(q, translation_type, completion_model, temp, max_tokens)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubmit_prompt\u001b[39m(q, translation_type, completion_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext1\u001b[39m\u001b[38;5;124m'\u001b[39m, temp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m900\u001b[39m):\n\u001b[1;32m      7\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m PROMPTS[translation_type]\n\u001b[0;32m----> 9\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubstitute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODELS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcompletion_model\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)       \n\u001b[1;32m     15\u001b[0m     r \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.10/site-packages/openai/api_requestor.py:216\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupplied_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.10/site-packages/openai/api_requestor.py:516\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m     _thread_context\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m _make_session()\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTIMEOUT_SECS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.10/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.10/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final = summarize_chunks(sub_sums, prompt='super_sum', max_tokens=900)\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5692e3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary: David Feng is looking for a way to use AWS Identity Center to push user groups to a third party service, Code Ocean, which allows scientists to do analysis on data in the cloud. Rob Young suggested that Cognito might be an option to enable the pushing of user groups, and Tim Dolbeare mentioned that he needs to be able to share with collaborators and partition access to resources within the cloud. Aiken David suggested that access to Code Ocean doesn't necessarily mean giving access to an S3 bucket, and all access is controlled by the app.\n",
      "\n",
      "In this meeting, the participants discussed the budget in the app, the ability to access plain vanilla S3 buckets, the need for an authenticator, and the need for an identity provider. They also discussed the issue of David's screen not being visible and the need to reset it.\n",
      "\n",
      "David Feng and Rob Young discussed the challenge of controlling access to their apps and data. They discussed the possibility of using Azure AD to manage access, as well as the possibility of using Orchid as an identity provider. They also discussed the possibility of federating with larger institutions to allow access to their apps and data.\n",
      "\n",
      "David Feng and Rob Young discussed the need for a single identity provider that could collaborate across different identity providers, such as Azure AD, COGNITO, and Octa. They discussed the possibility of using Azure AD B2C, but were looking for a more lightweight solution. AWS - Ashmeet Pahwa joined the conversation and asked for an overview of how Code Ocean works and how it allows access. David Feng explained that Code Ocean is an application that runs in AWS and has an internal lightweight user database. They discussed the possibility of using Azure AD for Allen Institute employees, and creating a second tenant that is an Azure B2C type of tenant to support Federated identity providers. The goal was to find an AWS product to take the place of the B2C tenant to simplify management and restrict access. However, they found that Identity Center does not support pushing groups to Code Ocean.\n",
      "\n",
      "Summary: The meeting transcript discussed a use case where a service is being developed that will associate users to projects with a role. The group discussed the possibility of using Azure AD B2C tenant as a resource of record for managing identities and groups, and setting up outbound skim token from Azure to AWS Identity Center. They also discussed the possibility of using attribute based access control and tags in the request to identify attributes in the request. They discussed the potential size limit of the JSON document that gets encrypted, and the possibility of having a power user role for Allen Institute data.\n",
      "\n",
      "David Feng and the other speakers discussed the need for an API to manage access to data stored in an S3 bucket. They discussed the need for different levels of access, such as read-only, read-write, and delete, and how to manage access to the S3 bucket. They also discussed the need for a service account to manage access to the bucket, and the need for a Python library to get the secret key and access the bucket. Finally, they discussed the need for a service to keep track of URLs to the files stored in the bucket.\n",
      "\n",
      "At the meeting, Rob Young discussed the need to automate the connection between users and projects managed in a database, and the need to assign resources or access to S3 buckets. Ashmeet Pahwa suggested looking into AWS Transfer Family, which is an SFTP server that connects to an S3 bucket and provides a file system-like interface. David Aiken suggested having a huddle with Ashmeet and Mike to brainstorm ideas and come up with proposals or designs. The meeting concluded with everyone agreeing to talk again on Monday.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sub_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b92f8e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In this meeting, the participants discussed the budget in the app, the ability to access plain vanilla S3 buckets, the need for an authenticator, and the need for an identity provider. They also discussed the issue of David's screen being blacked out and the need to reset it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mm = summarize_chunks([chunks[1]], prompt='summary', max_tokens=900)\n",
    "print(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "189ec7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Important Topics Discussed:\n",
      "- Using AWS Identity Center to push user groups to a third party service, Code Ocean\n",
      "- Using Cognito to enable the pushing of user groups\n",
      "- Access to Code Ocean and S3 buckets\n",
      "- Using Azure AD to manage access\n",
      "- Using Orchid as an identity provider\n",
      "- Using Azure AD B2C as a lightweight solution\n",
      "- Using Azure AD for Allen Institute employees\n",
      "- Using an API to manage access to data stored in an S3 bucket\n",
      "- Automating the connection between users and projects managed in a database\n",
      "- Assigning resources or access to S3 buckets\n",
      "- Using AWS Transfer Family\n",
      "\n",
      "Topic Summaries:\n",
      "- David Feng and Rob Young discussed the challenge of controlling access to their apps and data, and the possibility of using Azure AD, Orchid, and federating with larger institutions.\n",
      "- They discussed the need for a single identity provider that could collaborate across different identity providers, such as Azure AD, COGNITO, and Octa, and the possibility of using Azure AD B2C.\n",
      "- They discussed the need for an API to manage access to data stored in an S3 bucket, and the need for a service account to manage access to the bucket.\n",
      "- Rob Young discussed the need to automate the connection between users and projects managed in a database, and the need to assign resources or access to S3 buckets.\n",
      "\n",
      "Actions Decided Upon:\n",
      "- Have a huddle with Ashmeet and Mike to brainstorm ideas and come up with proposals or designs.\n",
      "- Talk again on Monday.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sum_sum = submit_prompt(sub_sums, 'super_sum', temp=0, max_tokens=1000)\n",
    "print(sum_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e0e6853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 chunks in this transcript\n",
      "Sub-summaries:\n",
      "\n",
      "Shoaib Mufti and Tim Dolbeare discussed the possibility of recording staff meetings and using language models to create summaries. They discussed the use of Code Ocean, a platform similar to Jupiter Labs, which allows data scientists to create capsules that encapsulate the compute environment and data. They also discussed the use of S3 as storage and a no-code workflow system. Tyler did not join the meeting.\n",
      "\n",
      "Tim Dolbeare discussed how Code Ocean can be used to host Python or R, and how administrators can define what machines are available to users. He also mentioned that only one scientist has used the drag and drop feature, and that administrators can set up permissions boundaries. Shoaib Mufti asked questions about the advantages of using Code Ocean, and Michael Wang and Rob Young discussed the cost of using Code Ocean and the need for good engineering practices.\n",
      "\n",
      "Rob and Tim discuss the use of Code Ocean for production workflows. They agree that the scientists should not be building production workflows, but rather the engineers should take possession of the workflows and optimize them for cost and speed. They also discuss the advantages of Code Ocean, such as visualizations, search features, and the ability to orchestrate and schedule resources. They agree that they should test the theory by running a workflow for a week and comparing the cost and performance of using Code Ocean versus optimizing the workflow.\n",
      "\n",
      "In this meeting, the participants discussed the potential use of Code Ocean for production workflows in AWS. They discussed the pros and cons of using Code Ocean and the criteria for determining when it would be appropriate to use it. They also discussed the need to do an analysis or write a position paper to make an informed decision. Finally, they discussed the possibility of connecting with an AWS solution architect to get an unbiased opinion.\n",
      "\n",
      "At the meeting, Shoaib Mufti discussed a presentation from June of last year by David. Tyler Mollenkopf provided details about the presentation, which included a visual of the workflow and ratings of the six jobs that the platform wanted to accomplish. Tyler also mentioned the risk of Code Ocean going under as a company and the need to mitigate that risk. Tim Dolbeare suggested getting names and a draft of an updated version of David's presentation. Shoaib Mufti agreed and suggested getting early bias and opinion from AWS. The meeting concluded with everyone thanking each other.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "infile = '/home/tim/work/projects/transcripts/CodeOceanAndAWSOPS_2023-02-15.docx'\n",
    "outfile = '/home/tim/work/projects/transcripts/CodeOceanAndAWSOPS_2023-02-15.txt'\n",
    "\n",
    "transcript_file = word_to_text(infile, outfile)\n",
    "\n",
    "raw_transcript = load_transcript(transcript_file)\n",
    "preprocessed = preprocess_transcript(raw_transcript)\n",
    "chunks = chunk_text(preprocessed, chunk_size=100)\n",
    "\n",
    "print(f\"There are {len(chunks)} chunks in this transcript\")\n",
    "\n",
    "sub_sums = summarize_chunks(chunks, prompt='summary', max_tokens=500)\n",
    "print(\"Sub-summaries:\")\n",
    "print(sub_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a2eed89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Important topics discussed:\n",
      "- Use of Code Ocean for production workflows\n",
      "- Advantages and disadvantages of using Code Ocean\n",
      "- Criteria for determining when to use Code Ocean\n",
      "- Risk of Code Ocean going under\n",
      "- Presentation from June of last year by David\n",
      "\n",
      "Summary of discussion:\n",
      "- Shoaib Mufti and Tim Dolbeare discussed the possibility of using Code Ocean, a platform similar to Jupiter Labs, for production workflows in AWS. \n",
      "- They discussed the pros and cons of using Code Ocean, such as visualizations, search features, and the ability to orchestrate and schedule resources. \n",
      "- They also discussed the need to do an analysis or write a position paper to make an informed decision, and the risk of Code Ocean going under as a company. \n",
      "- Tyler Mollenkopf provided details about the presentation from June of last year by David, which included a visual of the workflow and ratings of the six jobs that the platform wanted to accomplish.\n",
      "\n",
      "Actions decided upon:\n",
      "- Test the theory by running a workflow for a week and comparing the cost and performance of using Code Ocean versus optimizing the workflow.\n",
      "- Get early bias and opinion from AWS.\n",
      "- Get names and a draft of an updated version of David's presentation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sum_sum = submit_prompt(sub_sums, 'super_sum', temp=0, max_tokens=1000)\n",
    "print(sum_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b73e33c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: Please e-write the following text, removing anything taht doesn't seem usefull for summarization: \n",
      "avid\n",
      "And then you've got the UW data scientists, which is a different\n",
      "identity provider.\n",
      "\n",
      "Aiken, David\n",
      "And then you've got the AWS OPS, which is a different identity provider.\n",
      "\n",
      "Aiken, David\n",
      "So the question is, can we use a single identity provider to manage\n",
      "access to all of these different applications? And if so, what identity\n",
      "provider should we use?\n",
      "\n",
      "In this meeting, the participants discussed the need for a single identity provider to manage access to multiple applications. They discussed the possibility of using Azure AD, Orchid, or AWS Cognito as the identity provider. They also discussed the need to ensure that access is revoked when users leave the organization. They discussed the possibility of using Azure AD to manage access and roles, and the possibility of using AWS to manage access. No action was decided upon.\n",
      "\n",
      "Response: \n",
      "In this meeting, the participants discussed the need for a single identity provider to manage access to multiple applications. They discussed the possibility of using Azure AD, Orchid, or AWS Cognito. They also discussed the need to ensure access is revoked when users leave the organization. No action was decided upon.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = \"Please e-write the following text, removing anything taht doesn't seem usefull for summarization: \" + mm\n",
    "print(f\"prompt: {p}\")\n",
    "\n",
    "q = submit_prompt(p, 'free', temp=0, max_tokens=1000)\n",
    "\n",
    "print(f\"Response: {q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a62643b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actions Decided Upon:\n",
      "- Have a huddle with Ashmeet and Mike to brainstorm ideas and come back with proposals or designs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ss = submit_prompt(sub_sums, 'topics', max_tokens=2000)\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6ed7029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = chunk_text(ss)\n",
    "len(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3435742a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics discussed:\n",
      "- Using GPT 3 models to create notes\n",
      "- Using AWS Identity Center to manage users and user groups\n",
      "- Code Ocean requirement for identity management\n",
      "- Using Cognito in conjunction with Identity Center\n",
      "- Using GWT Team Bearer for identity management\n",
      "- Accessing S3 buckets through Code Ocean\n",
      "\n",
      "Summary:\n",
      "The group discussed using GPT 3 models to create notes, using AWS Identity Center to manage users and user groups, and the Code Ocean requirement for identity management. They discussed using Cognito in conjunction with Identity Center, using GWT Team Bearer for identity management, and accessing S3 buckets through Code Ocean.\n",
      "\n",
      "Actions Decided Upon:\n",
      "- Use GPT 3 models to create notes\n",
      "- Use AWS Identity Center to manage users and user groups\n",
      "- Use Cognito in conjunction with Identity Center\n",
      "- Use GWT Team Bearer for identity management\n",
      "- Access S3 buckets through Code Ocean\n",
      "\n",
      "avid\n",
      "And then you've got the UW data scientists, which is a different\n",
      "identity provider.\n",
      "\n",
      "Aiken, David\n",
      "And then you've got the AWS OPS, which is a different identity provider.\n",
      "\n",
      "Aiken, David\n",
      "So the question is, can we use a single identity provider to manage\n",
      "access to all of these different apps? And if so, what identity provider\n",
      "should we use?\n",
      "\n",
      "Summary:\n",
      "The meeting discussed the issue of managing access to various apps, such as Code Ocean, AWS Console, and other apps, for different users. The users include Allen Institute data scientists, UW data scientists, and AWS OPS. The discussion focused on the need to find an identity provider that can manage access to all of these different apps, and the possibility of using a single identity provider to do so. It was also discussed that using a single identity provider would allow for better control over user access, as it would be easier to revoke access when a user leaves or is no longer employed. No action was decided upon.\n",
      "\n",
      "Topics discussed:\n",
      "- Federating with Azure AD to give users access to different applications\n",
      "- Using AWS Cognito and Octa as potential solutions\n",
      "- Using Azure AD B2C\n",
      "- Using existing AD tenant\n",
      "- Using Code Ocean\n",
      "\n",
      "Summary:\n",
      "The group discussed the possibility of federating with Azure AD to give users access to different applications. They discussed using AWS Cognito and Octa as potential solutions, as well as Azure AD B2C and an existing AD tenant. They also discussed using Code Ocean, which is an application that runs in AWS and has an internal lightweight user database.\n",
      "\n",
      "Actions Decided Upon:\n",
      "- Do due diligence around looking at Cognito and Octa\n",
      "- Consider using Azure AD B2C\n",
      "- Consider using existing AD tenant\n",
      "\n",
      "Topics discussed: Using Azure AD B2C tenant to manage identities and groups, using AWS Identity Center to manage resources in AWS, using Azure AD to register Code Ocean, using Azure AD B2C tenant to manage projects and roles, using attribute based access control and tags to manage permissions.\n",
      "\n",
      "Summary: The meeting discussed using Azure AD B2C tenant to manage identities and groups, and using AWS Identity Center to manage resources in AWS. They discussed using Azure AD to register Code Ocean, and using Azure AD B2C tenant to manage projects and roles. They also discussed using attribute based access control and tags to manage permissions.\n",
      "\n",
      "Actions Decided Upon: Research if Azure AD B2C plays nice with Code Ocean, confirm if Azure AD B2C plays nice with Code Ocean, explore user replication in Azure AD, explore using a separate group for Code Ocean, explore using a custom script to push user attributes from Cognito User Pool, explore using a certificate and skim token to establish trust between Azure AD and AWS, explore using logic in the app to handle permissions, explore using cloud trail to identify attributes in the request.\n",
      "\n",
      "Topics discussed:\n",
      "- Creating roles for Allen Institute data\n",
      "- Creating multiple projects\n",
      "- Creating groups and assigning permissions\n",
      "- Creating roles for each project\n",
      "- Accessing S3 buckets\n",
      "- Automating connection between user and projects\n",
      "\n",
      "Summary:\n",
      "The meeting discussed creating roles for Allen Institute data, creating multiple projects, creating groups and assigning permissions, creating roles for each project, accessing S3 buckets, and automating the connection between user and projects. It was decided that there should be an owner, contributor, and reader role for each project, and that access to the S3 buckets should be managed by a service account with a secret key. It was also discussed that users should be given temporary credentials to access the S3 buckets, and that there should be a way to automate the connection between the user and the projects.\n",
      "\n",
      "Topics Discussed: \n",
      "1. Automating processes to ensure data is in sync\n",
      "2. Providing an abstraction layer that looks like a file system\n",
      "3. Managing permissions at that layer\n",
      "4. Looking into a service called Nasuni\n",
      "5. Looking into AWS Transfer Family\n",
      "\n",
      "Summary: The meeting discussed ways to automate processes to ensure data is in sync. They discussed providing an abstraction layer that looks like a file system and managing permissions at that layer. They looked into a service called Nasuni and AWS Transfer Family as potential solutions. The group decided to have a huddle with Ashmeet and Mike to brainstorm ideas and come back with proposals or designs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sub_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89a372c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0a1159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfcb8cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example file:\n",
    "infile = '/home/tim/work/projects/transcripts/AWS_LZ_Fun_Time_2023-02-10.docx'\n",
    "outfile = '/home/tim/work/projects/transcripts/AWS_LZ_Fun_Time_2023-02-10.txt'\n",
    "output = pypandoc.convert_file(infile, 'plain', outputfile=outfile)\n",
    "assert output == \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ff60a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f9b0a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a prompt and a question, return a translation from NL.\n",
    "# The key parameter that we're varying in his notebook is translation_type, which\n",
    "# selects for one of the prompts designed above.\n",
    "\n",
    "def submit_prompt(q, translation_type, completion_model='text1', temp=0, max_tokens=300):\n",
    "    \n",
    "    prompt = PROMPTS[translation_type]\n",
    "    \n",
    "    r = openai.Completion.create(\n",
    "        prompt=prompt.substitute({'q': q}),\n",
    "        temperature=temp,\n",
    "        max_tokens=max_tokens,\n",
    "        model=MODELS[completion_model]\n",
    "    )[\"choices\"][0][\"text\"].strip(\" \\n\")       \n",
    "    r = r.replace('A:', '').strip()\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f046cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_transcript(transcript):\n",
    "    # remove timestamps\n",
    "    temp = re.sub(\"[0-9]{1,2}:[0-9]{1,2}:[0-9]{1,2}\\.[0-9]{1,3} --> [0-9]{1,2}:[0-9]{1,2}:[0-9]{1,2}\\.[0-9]{1,3}\\n\", '', transcript)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bba49663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transcript(file_name):\n",
    "    with open(file_name) as f:\n",
    "        return f.read()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "427dd471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chars in transcript: 72076\n",
      "Number of lines in transcript: 3023\n",
      "number of chars after removing timestamps: 54298\n",
      "number of lines after removing timestamps: 2366\n",
      "Number of words after preprocessing: 10004\n"
     ]
    }
   ],
   "source": [
    "transcript_txt = '/home/tim/work/projects/transcripts/AWS_LZ_Fun_Time_2023-02-10.txt'\n",
    "part1 = load_transcript(transcript_txt)\n",
    "print(f\"number of chars in transcript: {len(part1)}\")\n",
    "l = part1.count('\\n')\n",
    "print(f\"Number of lines in transcript: {l}\")\n",
    "#part1_1 = part1[:3600]\n",
    "part1 = preprocess_transcript(part1)\n",
    "print(f\"number of chars after removing timestamps: {len(part1)}\")\n",
    "l = part1.count('\\n')\n",
    "print(f\"number of lines after removing timestamps: {l}\")\n",
    "word_count = len(part1.split())\n",
    "print(f\"Number of words after preprocessing: {word_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5590ae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 10000)\n",
      "(10000, 20000)\n",
      "(20000, 30000)\n",
      "(30000, 40000)\n",
      "(40000, 50000)\n",
      "(50000, 54298)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size = 10000\n",
    "total = len(part1)\n",
    "chunk_count = (total//chunk_size) + 1\n",
    "\n",
    "chunks = []\n",
    "for i in range(0,chunk_count):\n",
    "    #chunks.append(part1[[i*chunk_size]:chunk_size])\n",
    "    #print(i*chunk_size)\n",
    "    start = i*chunk_size\n",
    "    end = min(start+chunk_size, total)\n",
    "    print((start, end))\n",
    "    chunks.append(part1[start:end])\n",
    "\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36dae326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_chunks(chunks, prompt='summary', max_tokens=900):\n",
    "    r = ''\n",
    "    for chunk in chunks:\n",
    "        r += submit_prompt(chunk, prompt, max_tokens=max_tokens)\n",
    "        \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e78ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=10000):\n",
    "    total = len(text)\n",
    "    chunk_count = (total//chunk_size) + 1\n",
    "\n",
    "    chunks = []\n",
    "    for i in range(0,chunk_count):\n",
    "        start = i*chunk_size\n",
    "        end = min(start+chunk_size, total)\n",
    "        chunks.append(text[start:end])\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35c851f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "- Discussion of creating a transcript of the meeting\n",
      "- Discussion of using GPT 3 model to make notes\n",
      "- Discussion of using AWS Identity Center to manage users and user groups\n",
      "- Discussion of using Cognito in conjunction with AWS Identity Center\n",
      "- Discussion of using GWT Team Bearer for identity management\n",
      "- Discussion of using Octa for identity management\n",
      "- Discussion of access to code Ocean and S3 buckets\n",
      "- Discussion of merging Rob's platform with code Ocean\n",
      "\n",
      "Actions:\n",
      "- Download transcript and put it through GPT 3 model\n",
      "- Pull the trigger on setting up Octave\n",
      "- Chisel together a diagramSummary:\n",
      "- Discussed different identity providers for accessing apps, including Azure AD, Orchid, and AWS\n",
      "- Discussed the need to control access to apps, and the need to be able to revoke access when someone leaves an organization\n",
      "- Discussed the possibility of using Azure AD as an identity provider for the platform services maintained by Rob's team\n",
      "- Discussed the possibility of using Orchid as an identity provider for other apps, and the ability to manage access in one placeSummary:\n",
      "- The group is discussing how to collaborate across different identity providers to allow access to Code Ocean, an application running in AWS.\n",
      "- They are considering using Azure AD, Cognito, or Octa as the identity provider.\n",
      "- They are also considering using AWS Identity Center to manage groups and access to resources.\n",
      "- They are discussing the pros and cons of using Azure AD, Cognito, or Octa.\n",
      "- Code Ocean requires an identity provider that can push users and user groups down.\n",
      "\n",
      "Actions:\n",
      "- Do due diligence around looking at Cognito and Octa.\n",
      "- Consider using AWS Identity Center to manage groups and access to resources.Summary:\n",
      "- Rob Young discussed the Azure AD for Allen Institute employees and the use of a B2C tenant to manage groups and roles for platform services.\n",
      "- AWS - Ashmeet Pahwa suggested exploring user replication in Azure AD and creating a separate group for Code Ocean.\n",
      "- David Feng and Rob Young discussed the use case of creating a list of projects and associating users to them with roles, and using that to authorize access to data in databases and AWS resources.\n",
      "- AWS - Ashmeet Pahwa suggested using attribute based access control and tags in the request to identify attributes in the request.\n",
      "\n",
      "Actions:\n",
      "- Rob Young to do research on pushing groups to Code Ocean\n",
      "- David Feng to confirm that Azure AD B2C plays nice with Code Ocean\n",
      "- AWS - Ashmeet Pahwa to look into the use case and do research on itSummary:\n",
      "- Discussion of how to manage access to Allen Institute data\n",
      "- Need to create roles for users with different levels of access\n",
      "- Need to create a system to associate users with projects and filter data returned\n",
      "- Need to create a system to manage access to S3 buckets\n",
      "- Need to consider how to give users access to S3 buckets (e.g. signed URLs)\n",
      "\n",
      "Actions:\n",
      "- Create roles for users with different levels of access\n",
      "- Create a system to associate users with projects and filter data returned\n",
      "- Create a system to manage access to S3 buckets\n",
      "- Consider how to give users access to S3 buckets (e.g. signed URLs)Summary:\n",
      "- Discussed ways to automate the process of keeping data in sync\n",
      "- Discussed providing an abstraction layer that makes it look like a file system to make it easier for scientists to use\n",
      "- Discussed the service Nasuni, which works with AWS and POSIX compliant Linux and EQUATE\n",
      "- Discussed AWS Transfer Family, which is an SFTP server that connects to an S3 bucket and provides a list of files\n",
      "\n",
      "Actions:\n",
      "- Huddle with Ashmeet and Mike to brainstorm ideas and come up with proposals or designs\n",
      "- Keep chipping away at the challenge\n",
      "- Let John know about the code ocean thing\n",
      "- Consider the challenge and provide help if possible\n"
     ]
    }
   ],
   "source": [
    "r = summarize_chunks(chunks, max_tokens=900)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "faabd351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = chunk_text(r)\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ab79b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Summary:\\n- Discussion of creating a transcript of the meeting\\n- Discussion of using GPT 3 model to make notes\\n- Discussion of using AWS Identity Center to manage users and user groups\\n- Discussion of using Cognito in conjunction with AWS Identity Center\\n- Discussion of using GWT Team Bearer for identity management\\n- Discussion of using Octa for identity management\\n- Discussion of access to code Ocean and S3 buckets\\n- Discussion of merging Rob's platform with code Ocean\\n\\nActions:\\n- Download transcript and put it through GPT 3 model\\n- Pull the trigger on setting up Octave\\n- Chisel together a diagramSummary:\\n- Discussed different identity providers for accessing apps, including Azure AD, Orchid, and AWS\\n- Discussed the need to control access to apps, and the need to be able to revoke access when someone leaves an organization\\n- Discussed the possibility of using Azure AD as an identity provider for the platform services maintained by Rob's team\\n- Discussed the possibility of using Orchid as an identity provider for other apps, and the ability to manage access in one placeSummary:\\n- The group is discussing how to collaborate across different identity providers to allow access to Code Ocean, an application running in AWS.\\n- They are considering using Azure AD, Cognito, or Octa as the identity provider.\\n- They are also considering using AWS Identity Center to manage groups and access to resources.\\n- They are discussing the pros and cons of using Azure AD, Cognito, or Octa.\\n- Code Ocean requires an identity provider that can push users and user groups down.\\n\\nActions:\\n- Do due diligence around looking at Cognito and Octa.\\n- Consider using AWS Identity Center to manage groups and access to resources.Summary:\\n- Rob Young discussed the Azure AD for Allen Institute employees and the use of a B2C tenant to manage groups and roles for platform services.\\n- AWS - Ashmeet Pahwa suggested exploring user replication in Azure AD and creating a separate group for Code Ocean.\\n- David Feng and Rob Young discussed the use case of creating a list of projects and associating users to them with roles, and using that to authorize access to data in databases and AWS resources.\\n- AWS - Ashmeet Pahwa suggested using attribute based access control and tags in the request to identify attributes in the request.\\n\\nActions:\\n- Rob Young to do research on pushing groups to Code Ocean\\n- David Feng to confirm that Azure AD B2C plays nice with Code Ocean\\n- AWS - Ashmeet Pahwa to look into the use case and do research on itSummary:\\n- Discussion of how to manage access to Allen Institute data\\n- Need to create roles for users with different levels of access\\n- Need to create a system to associate users with projects and filter data returned\\n- Need to create a system to manage access to S3 buckets\\n- Need to consider how to give users access to S3 buckets (e.g. signed URLs)\\n\\nActions:\\n- Create roles for users with different levels of access\\n- Create a system to associate users with projects and filter data returned\\n- Create a system to manage access to S3 buckets\\n- Consider how to give users access to S3 buckets (e.g. signed URLs)Summary:\\n- Discussed ways to automate the process of keeping data in sync\\n- Discussed providing an abstraction layer that makes it look like a file system to make it easier for scientists to use\\n- Discussed the service Nasuni, which works with AWS and POSIX compliant Linux and EQUATE\\n- Discussed AWS Transfer Family, which is an SFTP server that connects to an S3 bucket and provides a list of files\\n\\nActions:\\n- Huddle with Ashmeet and Mike to brainstorm ideas and come up with proposals or designs\\n- Keep chipping away at the challenge\\n- Let John know about the code ocean thing\\n- Consider the challenge and provide help if possible\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "856a7100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Research Nasuni and AWS Transfer Family to see if they can be used to automate the process of keeping data in sync\n"
     ]
    }
   ],
   "source": [
    "f = summarize_chunks(t, max_tokens=900)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c50b031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "- Discussed ways to manage access to Allen Institute data\n",
      "- Discussed using Azure AD, Cognito, and Octa as identity providers\n",
      "- Discussed using AWS Identity Center to manage groups and access to resources\n",
      "- Discussed the need to control access to apps and the ability to revoke access when someone leaves an organization\n",
      "- Discussed automating the process of keeping data in sync\n",
      "- Discussed providing an abstraction layer to make it easier for scientists to use\n",
      "- Discussed the service Nasuni and AWS Transfer Family\n",
      "\n",
      "Actions:\n",
      "- Download transcript and put it through GPT 3 model\n",
      "- Pull the trigger on setting up Octave\n",
      "- Chisel together a diagram\n",
      "- Do due diligence around looking at Cognito and Octa\n",
      "- Consider using AWS Identity Center to manage groups and access to resources\n",
      "- Rob Young to do research on pushing groups to Code Ocean\n",
      "- David Feng to confirm that Azure AD B2C plays nice with Code Ocean\n",
      "- AWS - Ashmeet Pahwa to look into the use case and do research on it\n",
      "- Huddle with Ashmeet and Mike to brainstorm ideas and come up with proposals or designs\n",
      "- Keep chipping away at the challenge\n",
      "- Let John know about the code ocean thing\n",
      "- Consider the challenge and provide help if possible\n"
     ]
    }
   ],
   "source": [
    "r = submit_prompt(t[0], 'topics', max_tokens=900)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a555ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66539d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "re.sub(\"[0-9]{1,2}:[0-9]{1,2}:[0-9]{1,2}\\.[0-9]{1,3} --> [0-9]{1,2}:[0-9]{1,2}:[0-9]{1,2}\\.[0-9]{1,3}\", '', part1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a495a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r = submit_prompt(chunks[2]+chunks[3], 'topics', max_tokens=2000)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd50895",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Topics:\\n- User Management\\n- Configuration Steps\\n- Autoscaling\\n- HPC Setup\\n- Workflow Management\\n\\nSummary:\\n- User Management: Code Ocean offers integrations with Okta and Auth0 for identity management, which allows for assigning users to groups and sharing data and capsules with groups.\\n- Configuration Steps: Cloud formation template is used to deploy updates, which can take up to half an hour and cause an outage.\\n- Autoscaling: There is an auto scaling pool that pulls resources from, and users can request dedicated instances or spot instances.\\n- HPC Setup: Not currently supported, but may be in the near future.\\n- Workflow Management: Code Ocean uses Nextflow, which has a no-code script generator and allows users to write their own scripts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5001d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in chunks:\n",
    "    r = submit_prompt(chunk, 'topics', max_tokens=2000)\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88006e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = translate_question(r + \"\\nlol!\", 'jerry')\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0035de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
